{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>storm_id</th>\n",
       "      <th>storm_name</th>\n",
       "      <th>entry_time</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>entry_status</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>34kt_ne</th>\n",
       "      <th>...</th>\n",
       "      <th>34kt_sw</th>\n",
       "      <th>34kt_nw</th>\n",
       "      <th>50kt_ne</th>\n",
       "      <th>50kt_se</th>\n",
       "      <th>50kt_sw</th>\n",
       "      <th>50kt_nw</th>\n",
       "      <th>64kt_ne</th>\n",
       "      <th>64kt_se</th>\n",
       "      <th>64kt_sw</th>\n",
       "      <th>64kt_nw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14663</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-23 18:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.1N</td>\n",
       "      <td>75.1W</td>\n",
       "      <td>30</td>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14664</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 00:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.4N</td>\n",
       "      <td>75.7W</td>\n",
       "      <td>30</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14665</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 06:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TD</td>\n",
       "      <td>23.8N</td>\n",
       "      <td>76.2W</td>\n",
       "      <td>30</td>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14666</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 12:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>24.5N</td>\n",
       "      <td>76.5W</td>\n",
       "      <td>35</td>\n",
       "      <td>1006</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14667</th>\n",
       "      <td>AL122005</td>\n",
       "      <td>KATRINA</td>\n",
       "      <td>2005-08-24 18:00:00</td>\n",
       "      <td></td>\n",
       "      <td>TS</td>\n",
       "      <td>25.4N</td>\n",
       "      <td>76.9W</td>\n",
       "      <td>40</td>\n",
       "      <td>1003</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       storm_id storm_name          entry_time entry_id entry_status    lat  \\\n",
       "14663  AL122005    KATRINA 2005-08-23 18:00:00                    TD  23.1N   \n",
       "14664  AL122005    KATRINA 2005-08-24 00:00:00                    TD  23.4N   \n",
       "14665  AL122005    KATRINA 2005-08-24 06:00:00                    TD  23.8N   \n",
       "14666  AL122005    KATRINA 2005-08-24 12:00:00                    TS  24.5N   \n",
       "14667  AL122005    KATRINA 2005-08-24 18:00:00                    TS  25.4N   \n",
       "\n",
       "        long max_wind min_pressure 34kt_ne  ... 34kt_sw 34kt_nw 50kt_ne  \\\n",
       "14663  75.1W       30         1008       0  ...       0       0       0   \n",
       "14664  75.7W       30         1007       0  ...       0       0       0   \n",
       "14665  76.2W       30         1007       0  ...       0       0       0   \n",
       "14666  76.5W       35         1006      60  ...       0       0       0   \n",
       "14667  76.9W       40         1003      60  ...       0       0       0   \n",
       "\n",
       "      50kt_se 50kt_sw 50kt_nw 64kt_ne 64kt_se 64kt_sw 64kt_nw  \n",
       "14663       0       0       0       0       0       0       0  \n",
       "14664       0       0       0       0       0       0       0  \n",
       "14665       0       0       0       0       0       0       0  \n",
       "14666       0       0       0       0       0       0       0  \n",
       "14667       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import various libraries throughout the software\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from geopy.distance import great_circle as vc\n",
    "from copy import deepcopy\n",
    "import math as Math\n",
    "\n",
    "# Import from hurdat2 class in data folder and models class from hurricane-models folder\n",
    "from data.hurdat2 import hurdat2\n",
    "from errors.models import models\n",
    "\n",
    "# Initialize Dataframe for hurricanes and error database\n",
    "dataset = hurdat2(\"data/hurdat2.txt\") # Note that this data includes up to and including 2016\n",
    "errors = models(\"errors/1989-present_OFCL_v_BCD5_ind_ATL_TI_errors.txt\")\n",
    "\n",
    "# Show the first 5 records from Hurricane Katrina 2005 (AL122005)\n",
    "dataset.hurricanes.query('storm_id == \"AL122005\"').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data - Creating Hurricane Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Data Transformation Done!\n"
     ]
    }
   ],
   "source": [
    "# Create hurricane class\n",
    "class hurricane(object) : \n",
    "    def __init__(self, name, id) :\n",
    "        # Set instance variables\n",
    "        self.name = name\n",
    "        self.id = id\n",
    "        self.entries = dict()\n",
    "        self.models = dict()\n",
    "        \n",
    "        return\n",
    "    # Add hurricane track entry based on standard HURDAT2 format\n",
    "    def add_entry(self, array) :\n",
    "        entry = {\n",
    "            array[0] : { # dateteime of entry\n",
    "                'entry_time' : array[0], \n",
    "                'entry_id' : array[1],\n",
    "                'entry_status' : array[2],\n",
    "                'lat' : float(array[3][:-1]), # Convert to number from format '#.#N'\n",
    "                'long' : float(array[4][:-1]), # Convert to number from format '#.#W'\n",
    "                'max_wind' : float(array[5]),\n",
    "                'min_pressure' : None if array[6] is None else float(array[6]), # Early records are -999 or None\n",
    "                'wind_radii' :  array[7:], # Array based on HURDAT2 format\n",
    "                'distance':0,\n",
    "                'direction':0\n",
    "            }\n",
    "        }\n",
    "        self.entries.update(entry)\n",
    "        \n",
    "        return\n",
    "    def view_entry(self, key):\n",
    "        print(self.entries.get(datetime.datetime.strptime(key, '%Y-%m-%d %H:%M:%S')))\n",
    "        return\n",
    "    # Add hurricane model errors\n",
    "    def add_model(self, name, model) :\n",
    "        self.models[name] = model\n",
    "        \n",
    "        return\n",
    "# Storm ID Key for matching between datasets\n",
    "storm_ids = dict()\n",
    "\n",
    "# Parse in hurricanes\n",
    "hurricanes = dict()\n",
    "for index, entry in dataset.hurricanes.iterrows() :\n",
    "    #print(\"Transforming {}/{} entries from HURDAT2\".format(index + 1, len(dataset.hurricanes)), end = \"\\r\")\n",
    "    # New hurricane\n",
    "    if entry['storm_id'] not in hurricanes :\n",
    "        hurricanes[entry['storm_id']] = hurricane(entry['storm_name'], entry['storm_id'])\n",
    "        storm_ids[entry['storm_id']] = entry['storm_name']\n",
    "    # Add entry to hurricane\n",
    "    hurricanes[entry['storm_id']].add_entry(entry[2:])\n",
    "print(\"\\n Data Transformation Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Data Augmentation\n",
    "The shape on the input to the LSTM will be in a 3D array with the format [samples, timestamps, features]. In my case [9045, 4, 10] We will intitially begin with 1 time step and evaluate more can benefit our model. The output requires a 1 day forecast and observations without track data 1 days in the future will not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineered 764/764 hurricanes for 4 timestep(s)\n",
      "Done feature engineering hurricanes.\n",
      "preprocessed data  (9045, 4, 10)\n",
      "Scaling Data . . . (1 timestep for unqiue data)\n",
      "Feature engineered 764/764 hurricanes for 1 timestep(s)\n",
      "Done feature engineering hurricanes.\n",
      " Before scaling  [[  32.4          78.7          25.         1012.         1975.\n",
      "     6.           28.            6.           62.45981791  184.30495435]\n",
      " [  31.5          78.8          25.         1012.         1975.\n",
      "     6.           28.            0.           70.10132456  310.6687682 ]\n",
      " [  30.5          79.           25.         1013.         1975.\n",
      "     6.           27.           18.           69.09342174    0.        ]\n",
      " [  29.5          79.           25.         1013.         1975.\n",
      "     6.           27.           12.           69.09342174   -0.        ]] /n\n",
      " After scaling  [[ 0.54166667  0.69178082 -0.57142857  0.63157895 -1.38888889 -3.\n",
      "   0.75        0.         -0.13331622  0.03030072]\n",
      " [ 0.47916667  0.69520548 -0.57142857  0.63157895 -1.38888889 -3.\n",
      "   0.75       -0.5         0.00952019  0.73303025]\n",
      " [ 0.40972222  0.70205479 -0.57142857  0.68421053 -1.38888889 -3.\n",
      "   0.6875      1.         -0.00931971 -0.99464882]\n",
      " [ 0.34027778  0.70205479 -0.57142857  0.68421053 -1.38888889 -3.\n",
      "   0.6875      0.5        -0.00931971 -0.99464882]] /n\n",
      "Done scaling.\n"
     ]
    }
   ],
   "source": [
    "global_var = {'lat' : [], 'long' : [], 'max_wind' : [], 'min_pressure' : [], 'year' : [], 'month' : [], 'day' : [], 'hour' : [],\n",
    "         'distace' : [], 'angle' : []}\n",
    "count = 0\n",
    "def feature_extraction(timestep, previous) :\n",
    "    '''\n",
    "    PURPOSE: Calculate the features for a machine learning model within the context of hurricane-net\n",
    "    METHOD: Use the predictors and the calculation methodology defined in Knaff 2013\n",
    "    INPUT:  timestep - current dictionary of features in the hurricane object format\n",
    "            previous - previous timestep dictionary of features in the hurricane object format\n",
    "    OUTPUT: Dictionary of features\n",
    "    '''\n",
    "    \n",
    "    dLon =  timestep['long'] - previous['long'];  \n",
    "    temp = float(timestep['lat']) # p[0] is a str?\n",
    "    y_x = Math.sin(dLon) * Math.cos(temp);\n",
    "        \n",
    "    x_x = Math.cos(timestep['long']) * Math.sin(temp) - Math.sin(timestep['long']) * Math.cos(temp) * Math.cos(dLon);\n",
    "    brng = Math.degrees(Math.atan2(y_x, x_x)) \n",
    "    if (brng < 0):\n",
    "        brng+= 360;\n",
    "    \n",
    "    features = {\n",
    "        'lat' : timestep['lat'],\n",
    "        'long' : timestep['long'],\n",
    "        'max_wind' : timestep['max_wind'],\n",
    "        'min_pressure' : timestep['min_pressure'], \n",
    "        'year' : timestep['entry_time'].year,\n",
    "        'month' : timestep['entry_time'].month,\n",
    "        'day' : timestep['entry_time'].day,\n",
    "        'hour' : timestep['entry_time'].hour,\n",
    "        'distace': vc((previous['lat'],previous['long']),( timestep['lat'],timestep['long'])).miles,\n",
    "        'angle': brng,\n",
    "    }\n",
    "    \n",
    "    global count ;\n",
    "    count += 1\n",
    "    if count <10:\n",
    "        for key in features:\n",
    "            global_var[key].append(features[key])\n",
    "    return features\n",
    "    \n",
    "def storm_x_y(storm, timesteps = 1, lag = 6) :\n",
    "    '''\n",
    "    PURPOSE: Create independent and dependent samples for a machine learning model based on the timesteps\n",
    "    METHOD: Use the HURDAT2 database and a hurricane object as defined in hurricane-net for feature extraction\n",
    "    INPUT:  storm - hurricane object\n",
    "            timesteps - (default = 1) number of timesteps to calculate\n",
    "            include_none - (default = False) Boolean for including None in test data. Imputing function unavailable.\n",
    "            lag - (default = 24) lag in hours for the dependent variables up to 5 days\n",
    "    OUTPUT: Dictionary with independent (x) and dependent (y) values.\n",
    "    '''\n",
    "    x = []\n",
    "    # Create testing data structure with a dictionary\n",
    "    \n",
    "    times = [time * lag for time in range(1, (24 // lag) + 1)] # [6, 12, 18, 24]\n",
    "    y = dict([(time,[]) for time in times])\n",
    "    # Sort by entry time\n",
    "    entries = [entry[1] for entry in sorted(storm.entries.items())]\n",
    "    \n",
    "    for index in range(len(entries)) :\n",
    "        if index < timesteps : # Flag for insufficient initial time steps\n",
    "            continue\n",
    "\n",
    "        # If we're not including None values, check to see if there will be any\n",
    "        if None in [storm.entries.get(entries[index]['entry_time'] +\n",
    "                                         datetime.timedelta(hours = future)) for future in times] : break\n",
    "            \n",
    "        # Calculate time steps and their features for independent values\n",
    "        sample = []\n",
    "        sample_features = []\n",
    "        for step in range(timesteps) :\n",
    "            # Training sample\n",
    "            timestep = entries[index - step]\n",
    "            previous = entries[index - step - 1]\n",
    "            sample.append([timestep['entry_time']] + [[feature_extraction(timestep, previous)]])\n",
    "            sample_features.append(feature_extraction(timestep, previous))\n",
    "        x.append(sample) # Add our constructed sample\n",
    "        # Calculate time steps and their features for dependent values\n",
    "        for future in times :\n",
    "            timestep = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future))\n",
    "            previous = storm.entries.get(entries[index]['entry_time'] + datetime.timedelta(hours = future - lag))\n",
    "            \n",
    "            if timestep and previous: \n",
    "                y[future].append(feature_extraction(timestep, previous))\n",
    "            else :\n",
    "                y[future].append(None)\n",
    "    \n",
    "    # Return output, if there is no output, return None.\n",
    "    if len(x) is 0 :\n",
    "        return None\n",
    "    else:\n",
    "        return {'x': x, 'y': y}\n",
    "def shape(hurricanes, timesteps, remove_missing = True) :\n",
    "    '''\n",
    "    PURPOSE: Shape our data for input into machine learning models\n",
    "    METHOD: Use a numpy array to shape into (samples, timesteps, features)\n",
    "    INPUT:  hurricanes - dictionary of hurricane objects\n",
    "            timesteps - number of timesteps for the shape\n",
    "            remove_missing - boolean indicating whether the algorithm will disregard missing values\n",
    "    OUTPUT: numpy array of shape (samples, timesteps, 11) where 11 is the number of predictors in a hurricane object\n",
    "    '''\n",
    "    x = []\n",
    "    y = []\n",
    "    lag = 6# lag time in hours\n",
    "    precision = np.float64 # defines the precision of our data type\n",
    "    times = [time * lag for time in range(1, (24 // lag) + 1)] # Begin at lag hours with lag increments up to 120h inclusive\n",
    "    count = 0\n",
    "    for hurricane in hurricanes.values() :\n",
    "        count += 1\n",
    "        result = storm_x_y(hurricane, timesteps, lag)\n",
    "        if result is None :\n",
    "            continue\n",
    "        # Extract only the values from the strom features using our specified precision\n",
    "        hurricane_x = np.array(\n",
    "            [[list(sample[1][0].values()) for sample in x] for x in result['x']],\n",
    "            dtype = precision)\n",
    "        hurricane_y = np.array(\n",
    "            [[list(result['y'][time][index].values()) for time in times] for index in range(len(result['y'][lag]))],\n",
    "            dtype = precision)\n",
    "        # Disregard if algorithm requires no missing values\n",
    "        if remove_missing :\n",
    "            if (len(np.where(np.isnan(hurricane_x))[0]) > 0) or (len(np.where(np.isnan(hurricane_y))[0]) > 0) :\n",
    "                continue\n",
    "        # Add to our results\n",
    "        x.extend(hurricane_x)\n",
    "        y.extend(hurricane_y)\n",
    "        print(\"Feature engineered {}/{} hurricanes for {} timestep(s)\".format(count, len(hurricanes), timesteps), end = \"\\r\")\n",
    "    print(\"\\nDone feature engineering hurricanes.\")\n",
    "    \n",
    "    return {'x': np.array(x), 'y': np.array(y)}\n",
    "def scaler(processed_data, hurricanes) :\n",
    "    '''\n",
    "    PURPOSE: Scale our data using the RobustScaler method from the sklearn library\n",
    "    METHOD: Generate data using 1 timesteps and then remove the NaN or None types to use the scaler methods\n",
    "    INPUT:  hurricanes - dictionary of hurricane objects\n",
    "            processed_data - dictionary of x and y values of data produced by shape() function with no missing values\n",
    "    OUTPUT: 1) Scaled processed_data using RobustScaler\n",
    "            2) RobustScaler object fit with appropriate data\n",
    "    '''\n",
    "    print(\"Scaling Data . . . (1 timestep for unqiue data)\")\n",
    "    # Create our scaler\n",
    "    unqiue_data = shape(hurricanes, timesteps = 1)\n",
    "    x = np.reshape(unqiue_data['x'], (unqiue_data['x'].shape[0], -1))\n",
    "    x = np.delete(x, np.where(np.isnan(x))[0], 0)\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(x)\n",
    "    \n",
    "    # Scale our data\n",
    "    for index in range(len(processed_data['x'])) :\n",
    "        if index == 1:\n",
    "            print(' Before scaling ', processed_data['x'][index], '/n')\n",
    "            \n",
    "        # Scale our x\n",
    "        processed_data['x'][index] = scaler.transform(processed_data['x'][index])\n",
    "        if index == 1:\n",
    "            print(' After scaling ', processed_data['x'][index], '/n')\n",
    "        # Scale our y\n",
    "        processed_data['y'][index] = scaler.transform(processed_data['y'][index])\n",
    "    print(\"Done scaling.\")\n",
    "    return processed_data, scaler\n",
    "# Finalize and scale procesed data into a dictionary\n",
    "preprocessed_data = shape(hurricanes, timesteps = 4)\n",
    "print('preprocessed data ',preprocessed_data['x'].shape)\n",
    "preprocessed_data_unmodfied = deepcopy(preprocessed_data)\n",
    "processed_data, scaler = scaler(preprocessed_data, hurricanes)\n",
    "\n",
    "# df = pd.DataFrame(global_var, index = ['lat', 'long', 'max_wind', 'min_pressure', 'year', 'month', 'day', 'hour', 'distance', 'angle'])\n",
    "# df = pd.DataFrame([x for x in global_var])\n",
    "# df = pd.DataFrame.from_dict(global_var).head()\n",
    "df = pd.DataFrame(global_var)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(global_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>max_wind</th>\n",
       "      <th>min_pressure</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>distace</th>\n",
       "      <th>angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>30.324220</td>\n",
       "      <td>25.218066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>30.324220</td>\n",
       "      <td>25.218066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.3</td>\n",
       "      <td>80.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>30.342515</td>\n",
       "      <td>22.855027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.3</td>\n",
       "      <td>80.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>30.342515</td>\n",
       "      <td>22.855027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>43.664025</td>\n",
       "      <td>25.490162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>43.664025</td>\n",
       "      <td>25.490162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.7</td>\n",
       "      <td>79.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>19.344019</td>\n",
       "      <td>7.396331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.7</td>\n",
       "      <td>79.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>19.344019</td>\n",
       "      <td>7.396331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1970</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>48.257754</td>\n",
       "      <td>27.719906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lat  long  max_wind  min_pressure  year  month  day  hour    distace  \\\n",
       "0  12.5  80.5      25.0           NaN  1970      5   18    18  30.324220   \n",
       "1  12.5  80.5      25.0           NaN  1970      5   18    18  30.324220   \n",
       "2  12.3  80.1      25.0        1007.0  1970      5   18    12  30.342515   \n",
       "3  12.3  80.1      25.0        1007.0  1970      5   18    12  30.342515   \n",
       "4  12.1  79.7      25.0           NaN  1970      5   18     6  43.664025   \n",
       "5  12.1  79.7      25.0           NaN  1970      5   18     6  43.664025   \n",
       "6  11.7  79.2      25.0           NaN  1970      5   18     0  19.344019   \n",
       "7  11.7  79.2      25.0           NaN  1970      5   18     0  19.344019   \n",
       "8  13.0  81.0      25.0           NaN  1970      5   19     0  48.257754   \n",
       "\n",
       "       angle  \n",
       "0  25.218066  \n",
       "1  25.218066  \n",
       "2  22.855027  \n",
       "3  22.855027  \n",
       "4  25.490162  \n",
       "5  25.490162  \n",
       "6   7.396331  \n",
       "7   7.396331  \n",
       "8  27.719906  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting scaled y versus original x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(preprocessed_data_unmodfied['x'][:-1], preprocessed_data['y'][:-1], color='black')\n",
    "# plt.savefig('points_vs_distance', dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting scaled y against scaled x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(preprocessed_data['x'][:-1], preprocessed_data['y'][:-1], color='black')\n",
    "# plt.savefig('points_vs_distance', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7236, 4, 10)\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 4, 1024)           4239360   \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 4, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 4,240,385\n",
      "Trainable params: 4,240,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7236 samples, validate on 1809 samples\n",
      "Epoch 1/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.5100 - accuracy: 0.0024 - val_loss: 0.4226 - val_accuracy: 0.0029\n",
      "Epoch 2/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.4093 - accuracy: 0.0024 - val_loss: 0.3363 - val_accuracy: 0.0039\n",
      "Epoch 3/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.3282 - accuracy: 0.0028 - val_loss: 0.2753 - val_accuracy: 0.0048\n",
      "Epoch 4/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.2699 - accuracy: 0.0038 - val_loss: 0.2287 - val_accuracy: 0.0051\n",
      "Epoch 5/600\n",
      "7236/7236 [==============================] - 14s 2ms/step - loss: 0.2232 - accuracy: 0.0044 - val_loss: 0.1954 - val_accuracy: 0.0054\n",
      "Epoch 6/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.1888 - accuracy: 0.0046 - val_loss: 0.1757 - val_accuracy: 0.0050\n",
      "Epoch 7/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.1688 - accuracy: 0.0048 - val_loss: 0.1736 - val_accuracy: 0.0050\n",
      "Epoch 8/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.1683 - accuracy: 0.0047 - val_loss: 0.1728 - val_accuracy: 0.0053\n",
      "Epoch 9/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.1697 - accuracy: 0.0048 - val_loss: 0.1619 - val_accuracy: 0.0058\n",
      "Epoch 10/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.1602 - accuracy: 0.0048 - val_loss: 0.1481 - val_accuracy: 0.0059\n",
      "Epoch 11/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.1469 - accuracy: 0.0050 - val_loss: 0.1379 - val_accuracy: 0.0061\n",
      "Epoch 12/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.1367 - accuracy: 0.0051 - val_loss: 0.1316 - val_accuracy: 0.0061\n",
      "Epoch 13/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.1302 - accuracy: 0.0052 - val_loss: 0.1272 - val_accuracy: 0.0061\n",
      "Epoch 14/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.1256 - accuracy: 0.0053 - val_loss: 0.1234 - val_accuracy: 0.0061\n",
      "Epoch 15/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.1217 - accuracy: 0.0053 - val_loss: 0.1198 - val_accuracy: 0.0062\n",
      "Epoch 16/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.1181 - accuracy: 0.0054 - val_loss: 0.1161 - val_accuracy: 0.0062\n",
      "Epoch 17/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.1145 - accuracy: 0.0054 - val_loss: 0.1122 - val_accuracy: 0.0064\n",
      "Epoch 18/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.1106 - accuracy: 0.0054 - val_loss: 0.1082 - val_accuracy: 0.0064\n",
      "Epoch 19/600\n",
      "7236/7236 [==============================] - 14s 2ms/step - loss: 0.1065 - accuracy: 0.0054 - val_loss: 0.1047 - val_accuracy: 0.0064\n",
      "Epoch 20/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.1027 - accuracy: 0.0054 - val_loss: 0.1021 - val_accuracy: 0.0062\n",
      "Epoch 21/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0995 - accuracy: 0.0055 - val_loss: 0.1002 - val_accuracy: 0.0062\n",
      "Epoch 22/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0972 - accuracy: 0.0055 - val_loss: 0.0976 - val_accuracy: 0.0062\n",
      "Epoch 23/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0946 - accuracy: 0.0055 - val_loss: 0.0936 - val_accuracy: 0.0062\n",
      "Epoch 24/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0910 - accuracy: 0.0055 - val_loss: 0.0887 - val_accuracy: 0.0064\n",
      "Epoch 25/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0869 - accuracy: 0.0055 - val_loss: 0.0843 - val_accuracy: 0.0064\n",
      "Epoch 26/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0834 - accuracy: 0.0055 - val_loss: 0.0814 - val_accuracy: 0.0064\n",
      "Epoch 27/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0811 - accuracy: 0.0055 - val_loss: 0.0796 - val_accuracy: 0.0064\n",
      "Epoch 28/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0797 - accuracy: 0.0056 - val_loss: 0.0784 - val_accuracy: 0.0064\n",
      "Epoch 29/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0785 - accuracy: 0.0055 - val_loss: 0.0774 - val_accuracy: 0.0064\n",
      "Epoch 30/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0773 - accuracy: 0.0056 - val_loss: 0.0765 - val_accuracy: 0.0062\n",
      "Epoch 31/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0762 - accuracy: 0.0056 - val_loss: 0.0750 - val_accuracy: 0.0061\n",
      "Epoch 32/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0746 - accuracy: 0.0056 - val_loss: 0.0729 - val_accuracy: 0.0061\n",
      "Epoch 33/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0724 - accuracy: 0.0056 - val_loss: 0.0706 - val_accuracy: 0.0061\n",
      "Epoch 34/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0701 - accuracy: 0.0056 - val_loss: 0.0687 - val_accuracy: 0.0062\n",
      "Epoch 35/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0684 - accuracy: 0.0056 - val_loss: 0.0675 - val_accuracy: 0.0062\n",
      "Epoch 36/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0672 - accuracy: 0.0057 - val_loss: 0.0665 - val_accuracy: 0.0064\n",
      "Epoch 37/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0662 - accuracy: 0.0057 - val_loss: 0.0656 - val_accuracy: 0.0065\n",
      "Epoch 38/600\n",
      "7236/7236 [==============================] - 15s 2ms/step - loss: 0.0650 - accuracy: 0.0058 - val_loss: 0.0647 - val_accuracy: 0.0066\n",
      "Epoch 39/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0639 - accuracy: 0.0058 - val_loss: 0.0639 - val_accuracy: 0.0066\n",
      "Epoch 40/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0629 - accuracy: 0.0059 - val_loss: 0.0629 - val_accuracy: 0.0068\n",
      "Epoch 41/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0619 - accuracy: 0.0059 - val_loss: 0.0616 - val_accuracy: 0.0068\n",
      "Epoch 42/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0608 - accuracy: 0.0060 - val_loss: 0.0602 - val_accuracy: 0.0069\n",
      "Epoch 43/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0596 - accuracy: 0.0060 - val_loss: 0.0589 - val_accuracy: 0.0069\n",
      "Epoch 44/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0585 - accuracy: 0.0061 - val_loss: 0.0577 - val_accuracy: 0.0069\n",
      "Epoch 45/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0574 - accuracy: 0.0062 - val_loss: 0.0566 - val_accuracy: 0.0069\n",
      "Epoch 46/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0563 - accuracy: 0.0062 - val_loss: 0.0557 - val_accuracy: 0.0069\n",
      "Epoch 47/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0555 - accuracy: 0.0063 - val_loss: 0.0551 - val_accuracy: 0.0068\n",
      "Epoch 48/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0548 - accuracy: 0.0063 - val_loss: 0.0544 - val_accuracy: 0.0069\n",
      "Epoch 49/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0542 - accuracy: 0.0063 - val_loss: 0.0536 - val_accuracy: 0.0069\n",
      "Epoch 50/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0535 - accuracy: 0.0063 - val_loss: 0.0527 - val_accuracy: 0.0069\n",
      "Epoch 51/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0527 - accuracy: 0.0063 - val_loss: 0.0519 - val_accuracy: 0.0069\n",
      "Epoch 52/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0519 - accuracy: 0.0063 - val_loss: 0.0512 - val_accuracy: 0.0069\n",
      "Epoch 53/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0511 - accuracy: 0.0064 - val_loss: 0.0505 - val_accuracy: 0.0069\n",
      "Epoch 54/600\n",
      "7236/7236 [==============================] - 14s 2ms/step - loss: 0.0504 - accuracy: 0.0064 - val_loss: 0.0499 - val_accuracy: 0.0069\n",
      "Epoch 55/600\n",
      "7236/7236 [==============================] - 15s 2ms/step - loss: 0.0497 - accuracy: 0.0064 - val_loss: 0.0493 - val_accuracy: 0.0069\n",
      "Epoch 56/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0490 - accuracy: 0.0064 - val_loss: 0.0487 - val_accuracy: 0.0069\n",
      "Epoch 57/600\n",
      "7236/7236 [==============================] - 14s 2ms/step - loss: 0.0484 - accuracy: 0.0064 - val_loss: 0.0481 - val_accuracy: 0.0069\n",
      "Epoch 58/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0477 - accuracy: 0.0064 - val_loss: 0.0473 - val_accuracy: 0.0070\n",
      "Epoch 59/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0471 - accuracy: 0.0064 - val_loss: 0.0466 - val_accuracy: 0.0070\n",
      "Epoch 60/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0464 - accuracy: 0.0064 - val_loss: 0.0459 - val_accuracy: 0.0070\n",
      "Epoch 61/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0458 - accuracy: 0.0064 - val_loss: 0.0452 - val_accuracy: 0.0070\n",
      "Epoch 62/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0451 - accuracy: 0.0064 - val_loss: 0.0445 - val_accuracy: 0.0070\n",
      "Epoch 63/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0444 - accuracy: 0.0064 - val_loss: 0.0439 - val_accuracy: 0.0070\n",
      "Epoch 64/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0438 - accuracy: 0.0064 - val_loss: 0.0433 - val_accuracy: 0.0069\n",
      "Epoch 65/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0432 - accuracy: 0.0064 - val_loss: 0.0426 - val_accuracy: 0.0069\n",
      "Epoch 66/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0426 - accuracy: 0.0064 - val_loss: 0.0420 - val_accuracy: 0.0069\n",
      "Epoch 67/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0420 - accuracy: 0.0064 - val_loss: 0.0414 - val_accuracy: 0.0069\n",
      "Epoch 68/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0414 - accuracy: 0.0064 - val_loss: 0.0407 - val_accuracy: 0.0069\n",
      "Epoch 69/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0408 - accuracy: 0.0064 - val_loss: 0.0401 - val_accuracy: 0.0069\n",
      "Epoch 70/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0402 - accuracy: 0.0064 - val_loss: 0.0395 - val_accuracy: 0.0069\n",
      "Epoch 71/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0396 - accuracy: 0.0064 - val_loss: 0.0390 - val_accuracy: 0.0070\n",
      "Epoch 72/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0391 - accuracy: 0.0064 - val_loss: 0.0384 - val_accuracy: 0.0070\n",
      "Epoch 73/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0385 - accuracy: 0.0065 - val_loss: 0.0379 - val_accuracy: 0.0070\n",
      "Epoch 74/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0379 - accuracy: 0.0065 - val_loss: 0.0373 - val_accuracy: 0.0070\n",
      "Epoch 75/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0374 - accuracy: 0.0065 - val_loss: 0.0368 - val_accuracy: 0.0070\n",
      "Epoch 76/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0368 - accuracy: 0.0065 - val_loss: 0.0362 - val_accuracy: 0.0070\n",
      "Epoch 77/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0363 - accuracy: 0.0065 - val_loss: 0.0357 - val_accuracy: 0.0070\n",
      "Epoch 78/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0357 - accuracy: 0.0065 - val_loss: 0.0352 - val_accuracy: 0.0070\n",
      "Epoch 79/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0352 - accuracy: 0.0065 - val_loss: 0.0346 - val_accuracy: 0.0070\n",
      "Epoch 80/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0347 - accuracy: 0.0065 - val_loss: 0.0340 - val_accuracy: 0.0070\n",
      "Epoch 81/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0341 - accuracy: 0.0065 - val_loss: 0.0335 - val_accuracy: 0.0070\n",
      "Epoch 82/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0336 - accuracy: 0.0065 - val_loss: 0.0329 - val_accuracy: 0.0070\n",
      "Epoch 83/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0331 - accuracy: 0.0065 - val_loss: 0.0324 - val_accuracy: 0.0070\n",
      "Epoch 84/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0326 - accuracy: 0.0065 - val_loss: 0.0319 - val_accuracy: 0.0070\n",
      "Epoch 85/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0321 - accuracy: 0.0065 - val_loss: 0.0314 - val_accuracy: 0.0072\n",
      "Epoch 86/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0316 - accuracy: 0.0065 - val_loss: 0.0309 - val_accuracy: 0.0072\n",
      "Epoch 87/600\n",
      "7236/7236 [==============================] - 14s 2ms/step - loss: 0.0311 - accuracy: 0.0065 - val_loss: 0.0304 - val_accuracy: 0.0072\n",
      "Epoch 88/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0306 - accuracy: 0.0065 - val_loss: 0.0299 - val_accuracy: 0.0072\n",
      "Epoch 89/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0301 - accuracy: 0.0065 - val_loss: 0.0294 - val_accuracy: 0.0072\n",
      "Epoch 90/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0296 - accuracy: 0.0065 - val_loss: 0.0290 - val_accuracy: 0.0072\n",
      "Epoch 91/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0292 - accuracy: 0.0065 - val_loss: 0.0285 - val_accuracy: 0.0072\n",
      "Epoch 92/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0287 - accuracy: 0.0065 - val_loss: 0.0280 - val_accuracy: 0.0072\n",
      "Epoch 93/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0283 - accuracy: 0.0065 - val_loss: 0.0276 - val_accuracy: 0.0072\n",
      "Epoch 94/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0278 - accuracy: 0.0065 - val_loss: 0.0272 - val_accuracy: 0.0072\n",
      "Epoch 95/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0274 - accuracy: 0.0065 - val_loss: 0.0267 - val_accuracy: 0.0072\n",
      "Epoch 96/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0270 - accuracy: 0.0065 - val_loss: 0.0263 - val_accuracy: 0.0072\n",
      "Epoch 97/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0265 - accuracy: 0.0065 - val_loss: 0.0258 - val_accuracy: 0.0072\n",
      "Epoch 98/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0261 - accuracy: 0.0065 - val_loss: 0.0254 - val_accuracy: 0.0072\n",
      "Epoch 99/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0257 - accuracy: 0.0065 - val_loss: 0.0250 - val_accuracy: 0.0072\n",
      "Epoch 100/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0253 - accuracy: 0.0065 - val_loss: 0.0246 - val_accuracy: 0.0072\n",
      "Epoch 101/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0250 - accuracy: 0.0065 - val_loss: 0.0243 - val_accuracy: 0.0072\n",
      "Epoch 102/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0246 - accuracy: 0.0065 - val_loss: 0.0239 - val_accuracy: 0.0072\n",
      "Epoch 103/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0242 - accuracy: 0.0065 - val_loss: 0.0235 - val_accuracy: 0.0072\n",
      "Epoch 104/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0239 - accuracy: 0.0065 - val_loss: 0.0232 - val_accuracy: 0.0072\n",
      "Epoch 105/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0235 - accuracy: 0.0065 - val_loss: 0.0229 - val_accuracy: 0.0072\n",
      "Epoch 106/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0232 - accuracy: 0.0065 - val_loss: 0.0226 - val_accuracy: 0.0072\n",
      "Epoch 107/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0229 - accuracy: 0.0065 - val_loss: 0.0223 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0226 - accuracy: 0.0065 - val_loss: 0.0220 - val_accuracy: 0.0072\n",
      "Epoch 109/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0223 - accuracy: 0.0065 - val_loss: 0.0217 - val_accuracy: 0.0072\n",
      "Epoch 110/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0220 - accuracy: 0.0065 - val_loss: 0.0214 - val_accuracy: 0.0072\n",
      "Epoch 111/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0218 - accuracy: 0.0065 - val_loss: 0.0212 - val_accuracy: 0.0072\n",
      "Epoch 112/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0215 - accuracy: 0.0065 - val_loss: 0.0209 - val_accuracy: 0.0072\n",
      "Epoch 113/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0213 - accuracy: 0.0065 - val_loss: 0.0207 - val_accuracy: 0.0072\n",
      "Epoch 114/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0210 - accuracy: 0.0065 - val_loss: 0.0205 - val_accuracy: 0.0072\n",
      "Epoch 115/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0208 - accuracy: 0.0065 - val_loss: 0.0203 - val_accuracy: 0.0072\n",
      "Epoch 116/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0206 - accuracy: 0.0065 - val_loss: 0.0201 - val_accuracy: 0.0072\n",
      "Epoch 117/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0204 - accuracy: 0.0065 - val_loss: 0.0199 - val_accuracy: 0.0072\n",
      "Epoch 118/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0203 - accuracy: 0.0065 - val_loss: 0.0197 - val_accuracy: 0.0072\n",
      "Epoch 119/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0201 - accuracy: 0.0065 - val_loss: 0.0196 - val_accuracy: 0.0072\n",
      "Epoch 120/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0199 - accuracy: 0.0065 - val_loss: 0.0194 - val_accuracy: 0.0072\n",
      "Epoch 121/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0198 - accuracy: 0.0065 - val_loss: 0.0193 - val_accuracy: 0.0072\n",
      "Epoch 122/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0196 - accuracy: 0.0065 - val_loss: 0.0192 - val_accuracy: 0.0072\n",
      "Epoch 123/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0195 - accuracy: 0.0065 - val_loss: 0.0190 - val_accuracy: 0.0072\n",
      "Epoch 124/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0194 - accuracy: 0.0065 - val_loss: 0.0189 - val_accuracy: 0.0072\n",
      "Epoch 125/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0193 - accuracy: 0.0065 - val_loss: 0.0188 - val_accuracy: 0.0072\n",
      "Epoch 126/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0192 - accuracy: 0.0065 - val_loss: 0.0187 - val_accuracy: 0.0072\n",
      "Epoch 127/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0191 - accuracy: 0.0065 - val_loss: 0.0186 - val_accuracy: 0.0072\n",
      "Epoch 128/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0190 - accuracy: 0.0065 - val_loss: 0.0186 - val_accuracy: 0.0072\n",
      "Epoch 129/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0189 - accuracy: 0.0065 - val_loss: 0.0185 - val_accuracy: 0.0072\n",
      "Epoch 130/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0188 - accuracy: 0.0065 - val_loss: 0.0184 - val_accuracy: 0.0072\n",
      "Epoch 131/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0188 - accuracy: 0.0065 - val_loss: 0.0184 - val_accuracy: 0.0072\n",
      "Epoch 132/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0187 - accuracy: 0.0065 - val_loss: 0.0183 - val_accuracy: 0.0072\n",
      "Epoch 133/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0186 - accuracy: 0.0065 - val_loss: 0.0183 - val_accuracy: 0.0072\n",
      "Epoch 134/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0186 - accuracy: 0.0065 - val_loss: 0.0182 - val_accuracy: 0.0072\n",
      "Epoch 135/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0185 - accuracy: 0.0065 - val_loss: 0.0182 - val_accuracy: 0.0072\n",
      "Epoch 136/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0185 - accuracy: 0.0065 - val_loss: 0.0181 - val_accuracy: 0.0072\n",
      "Epoch 137/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0184 - accuracy: 0.0065 - val_loss: 0.0181 - val_accuracy: 0.0072\n",
      "Epoch 138/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0184 - accuracy: 0.0065 - val_loss: 0.0180 - val_accuracy: 0.0072\n",
      "Epoch 139/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0183 - accuracy: 0.0065 - val_loss: 0.0180 - val_accuracy: 0.0072\n",
      "Epoch 140/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0183 - accuracy: 0.0065 - val_loss: 0.0179 - val_accuracy: 0.0072\n",
      "Epoch 141/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0183 - accuracy: 0.0065 - val_loss: 0.0179 - val_accuracy: 0.0072\n",
      "Epoch 142/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0182 - accuracy: 0.0065 - val_loss: 0.0179 - val_accuracy: 0.0072\n",
      "Epoch 143/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0182 - accuracy: 0.0065 - val_loss: 0.0178 - val_accuracy: 0.0072\n",
      "Epoch 144/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0181 - accuracy: 0.0065 - val_loss: 0.0178 - val_accuracy: 0.0072\n",
      "Epoch 145/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0181 - accuracy: 0.0065 - val_loss: 0.0178 - val_accuracy: 0.0072\n",
      "Epoch 146/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0181 - accuracy: 0.0065 - val_loss: 0.0177 - val_accuracy: 0.0072\n",
      "Epoch 147/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0180 - accuracy: 0.0065 - val_loss: 0.0177 - val_accuracy: 0.0072\n",
      "Epoch 148/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0180 - accuracy: 0.0065 - val_loss: 0.0177 - val_accuracy: 0.0072\n",
      "Epoch 149/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0180 - accuracy: 0.0065 - val_loss: 0.0177 - val_accuracy: 0.0072\n",
      "Epoch 150/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0179 - accuracy: 0.0065 - val_loss: 0.0176 - val_accuracy: 0.0072\n",
      "Epoch 151/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0179 - accuracy: 0.0065 - val_loss: 0.0176 - val_accuracy: 0.0072\n",
      "Epoch 152/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0178 - accuracy: 0.0065 - val_loss: 0.0176 - val_accuracy: 0.0072\n",
      "Epoch 153/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0178 - accuracy: 0.0065 - val_loss: 0.0175 - val_accuracy: 0.0072\n",
      "Epoch 154/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0178 - accuracy: 0.0065 - val_loss: 0.0175 - val_accuracy: 0.0072\n",
      "Epoch 155/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0177 - accuracy: 0.0065 - val_loss: 0.0175 - val_accuracy: 0.0072\n",
      "Epoch 156/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0177 - accuracy: 0.0065 - val_loss: 0.0174 - val_accuracy: 0.0072\n",
      "Epoch 157/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0177 - accuracy: 0.0065 - val_loss: 0.0174 - val_accuracy: 0.0072\n",
      "Epoch 158/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0176 - accuracy: 0.0065 - val_loss: 0.0174 - val_accuracy: 0.0072\n",
      "Epoch 159/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0176 - accuracy: 0.0065 - val_loss: 0.0173 - val_accuracy: 0.0072\n",
      "Epoch 160/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0175 - accuracy: 0.0065 - val_loss: 0.0173 - val_accuracy: 0.0072\n",
      "Epoch 161/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0175 - accuracy: 0.0065 - val_loss: 0.0173 - val_accuracy: 0.0072\n",
      "Epoch 162/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0175 - accuracy: 0.0065 - val_loss: 0.0172 - val_accuracy: 0.0072\n",
      "Epoch 163/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0174 - accuracy: 0.0065 - val_loss: 0.0172 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0174 - accuracy: 0.0065 - val_loss: 0.0172 - val_accuracy: 0.0072\n",
      "Epoch 165/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0173 - accuracy: 0.0065 - val_loss: 0.0171 - val_accuracy: 0.0072\n",
      "Epoch 166/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0173 - accuracy: 0.0065 - val_loss: 0.0171 - val_accuracy: 0.0072\n",
      "Epoch 167/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0172 - accuracy: 0.0065 - val_loss: 0.0171 - val_accuracy: 0.0072\n",
      "Epoch 168/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0172 - accuracy: 0.0065 - val_loss: 0.0170 - val_accuracy: 0.0072\n",
      "Epoch 169/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0172 - accuracy: 0.0065 - val_loss: 0.0170 - val_accuracy: 0.0072\n",
      "Epoch 170/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0171 - accuracy: 0.0065 - val_loss: 0.0170 - val_accuracy: 0.0072\n",
      "Epoch 171/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0171 - accuracy: 0.0065 - val_loss: 0.0169 - val_accuracy: 0.0072\n",
      "Epoch 172/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0170 - accuracy: 0.0065 - val_loss: 0.0169 - val_accuracy: 0.0072\n",
      "Epoch 173/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0170 - accuracy: 0.0065 - val_loss: 0.0169 - val_accuracy: 0.0072\n",
      "Epoch 174/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0169 - accuracy: 0.0065 - val_loss: 0.0168 - val_accuracy: 0.0072\n",
      "Epoch 175/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0169 - accuracy: 0.0065 - val_loss: 0.0168 - val_accuracy: 0.0072\n",
      "Epoch 176/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0168 - accuracy: 0.0065 - val_loss: 0.0168 - val_accuracy: 0.0072\n",
      "Epoch 177/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0168 - accuracy: 0.0065 - val_loss: 0.0167 - val_accuracy: 0.0072\n",
      "Epoch 178/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0168 - accuracy: 0.0065 - val_loss: 0.0167 - val_accuracy: 0.0072\n",
      "Epoch 179/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0167 - accuracy: 0.0065 - val_loss: 0.0166 - val_accuracy: 0.0072\n",
      "Epoch 180/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0167 - accuracy: 0.0065 - val_loss: 0.0166 - val_accuracy: 0.0072\n",
      "Epoch 181/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0166 - accuracy: 0.0065 - val_loss: 0.0166 - val_accuracy: 0.0072\n",
      "Epoch 182/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0166 - accuracy: 0.0065 - val_loss: 0.0165 - val_accuracy: 0.0072\n",
      "Epoch 183/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0165 - accuracy: 0.0065 - val_loss: 0.0165 - val_accuracy: 0.0072\n",
      "Epoch 184/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0165 - accuracy: 0.0065 - val_loss: 0.0164 - val_accuracy: 0.0072\n",
      "Epoch 185/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0164 - accuracy: 0.0065 - val_loss: 0.0164 - val_accuracy: 0.0072\n",
      "Epoch 186/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0164 - accuracy: 0.0065 - val_loss: 0.0164 - val_accuracy: 0.0072\n",
      "Epoch 187/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0163 - accuracy: 0.0065 - val_loss: 0.0163 - val_accuracy: 0.0072\n",
      "Epoch 188/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0163 - accuracy: 0.0066 - val_loss: 0.0163 - val_accuracy: 0.0072\n",
      "Epoch 189/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0162 - accuracy: 0.0066 - val_loss: 0.0162 - val_accuracy: 0.0072\n",
      "Epoch 190/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0162 - accuracy: 0.0066 - val_loss: 0.0162 - val_accuracy: 0.0072\n",
      "Epoch 191/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0161 - accuracy: 0.0066 - val_loss: 0.0162 - val_accuracy: 0.0072\n",
      "Epoch 192/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0161 - accuracy: 0.0066 - val_loss: 0.0161 - val_accuracy: 0.0072\n",
      "Epoch 193/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0160 - accuracy: 0.0066 - val_loss: 0.0161 - val_accuracy: 0.0072\n",
      "Epoch 194/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0160 - accuracy: 0.0066 - val_loss: 0.0160 - val_accuracy: 0.0072\n",
      "Epoch 195/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0159 - accuracy: 0.0066 - val_loss: 0.0160 - val_accuracy: 0.0072\n",
      "Epoch 196/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0159 - accuracy: 0.0066 - val_loss: 0.0159 - val_accuracy: 0.0072\n",
      "Epoch 197/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0158 - accuracy: 0.0066 - val_loss: 0.0159 - val_accuracy: 0.0072\n",
      "Epoch 198/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0158 - accuracy: 0.0066 - val_loss: 0.0158 - val_accuracy: 0.0072\n",
      "Epoch 199/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0157 - accuracy: 0.0066 - val_loss: 0.0158 - val_accuracy: 0.0072\n",
      "Epoch 200/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0156 - accuracy: 0.0066 - val_loss: 0.0158 - val_accuracy: 0.0072\n",
      "Epoch 201/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0156 - accuracy: 0.0066 - val_loss: 0.0157 - val_accuracy: 0.0072\n",
      "Epoch 202/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0155 - accuracy: 0.0066 - val_loss: 0.0157 - val_accuracy: 0.0072\n",
      "Epoch 203/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0155 - accuracy: 0.0066 - val_loss: 0.0156 - val_accuracy: 0.0072\n",
      "Epoch 204/600\n",
      "7236/7236 [==============================] - 13s 2ms/step - loss: 0.0154 - accuracy: 0.0066 - val_loss: 0.0156 - val_accuracy: 0.0072\n",
      "Epoch 205/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0154 - accuracy: 0.0066 - val_loss: 0.0155 - val_accuracy: 0.0072\n",
      "Epoch 206/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0153 - accuracy: 0.0066 - val_loss: 0.0155 - val_accuracy: 0.0072\n",
      "Epoch 207/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0153 - accuracy: 0.0066 - val_loss: 0.0154 - val_accuracy: 0.0072\n",
      "Epoch 208/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0152 - accuracy: 0.0066 - val_loss: 0.0153 - val_accuracy: 0.0072\n",
      "Epoch 209/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0151 - accuracy: 0.0066 - val_loss: 0.0153 - val_accuracy: 0.0072\n",
      "Epoch 210/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0151 - accuracy: 0.0066 - val_loss: 0.0152 - val_accuracy: 0.0072\n",
      "Epoch 211/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0150 - accuracy: 0.0066 - val_loss: 0.0152 - val_accuracy: 0.0072\n",
      "Epoch 212/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0150 - accuracy: 0.0066 - val_loss: 0.0151 - val_accuracy: 0.0072\n",
      "Epoch 213/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0149 - accuracy: 0.0066 - val_loss: 0.0151 - val_accuracy: 0.0072\n",
      "Epoch 214/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0148 - accuracy: 0.0066 - val_loss: 0.0150 - val_accuracy: 0.0072\n",
      "Epoch 215/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0148 - accuracy: 0.0066 - val_loss: 0.0150 - val_accuracy: 0.0072\n",
      "Epoch 216/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0147 - accuracy: 0.0066 - val_loss: 0.0149 - val_accuracy: 0.0072\n",
      "Epoch 217/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0147 - accuracy: 0.0066 - val_loss: 0.0148 - val_accuracy: 0.0072\n",
      "Epoch 218/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0146 - accuracy: 0.0066 - val_loss: 0.0148 - val_accuracy: 0.0072\n",
      "Epoch 219/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0145 - accuracy: 0.0066 - val_loss: 0.0147 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0145 - accuracy: 0.0066 - val_loss: 0.0147 - val_accuracy: 0.0072\n",
      "Epoch 221/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0144 - accuracy: 0.0066 - val_loss: 0.0146 - val_accuracy: 0.0072\n",
      "Epoch 222/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0144 - accuracy: 0.0066 - val_loss: 0.0145 - val_accuracy: 0.0072\n",
      "Epoch 223/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0143 - accuracy: 0.0066 - val_loss: 0.0145 - val_accuracy: 0.0072\n",
      "Epoch 224/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0142 - accuracy: 0.0066 - val_loss: 0.0144 - val_accuracy: 0.0072\n",
      "Epoch 225/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0142 - accuracy: 0.0066 - val_loss: 0.0144 - val_accuracy: 0.0072\n",
      "Epoch 226/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0141 - accuracy: 0.0066 - val_loss: 0.0144 - val_accuracy: 0.0072\n",
      "Epoch 227/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0141 - accuracy: 0.0066 - val_loss: 0.0146 - val_accuracy: 0.0072\n",
      "Epoch 228/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0143 - accuracy: 0.0066 - val_loss: 0.0150 - val_accuracy: 0.0072\n",
      "Epoch 229/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0147 - accuracy: 0.0066 - val_loss: 0.0147 - val_accuracy: 0.0072\n",
      "Epoch 230/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0144 - accuracy: 0.0066 - val_loss: 0.0141 - val_accuracy: 0.0072\n",
      "Epoch 231/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0138 - accuracy: 0.0066 - val_loss: 0.0145 - val_accuracy: 0.0072\n",
      "Epoch 232/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0142 - accuracy: 0.0066 - val_loss: 0.0145 - val_accuracy: 0.0072\n",
      "Epoch 233/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0142 - accuracy: 0.0066 - val_loss: 0.0140 - val_accuracy: 0.0072\n",
      "Epoch 234/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0137 - accuracy: 0.0066 - val_loss: 0.0142 - val_accuracy: 0.0072\n",
      "Epoch 235/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0140 - accuracy: 0.0066 - val_loss: 0.0142 - val_accuracy: 0.0072\n",
      "Epoch 236/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0139 - accuracy: 0.0066 - val_loss: 0.0139 - val_accuracy: 0.0072\n",
      "Epoch 237/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0136 - accuracy: 0.0066 - val_loss: 0.0141 - val_accuracy: 0.0072\n",
      "Epoch 238/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0138 - accuracy: 0.0066 - val_loss: 0.0139 - val_accuracy: 0.0072\n",
      "Epoch 239/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0136 - accuracy: 0.0066 - val_loss: 0.0138 - val_accuracy: 0.0072\n",
      "Epoch 240/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0134 - accuracy: 0.0066 - val_loss: 0.0139 - val_accuracy: 0.0072\n",
      "Epoch 241/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0136 - accuracy: 0.0066 - val_loss: 0.0137 - val_accuracy: 0.0072\n",
      "Epoch 242/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0134 - accuracy: 0.0066 - val_loss: 0.0137 - val_accuracy: 0.0072\n",
      "Epoch 243/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0133 - accuracy: 0.0066 - val_loss: 0.0138 - val_accuracy: 0.0072\n",
      "Epoch 244/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0134 - accuracy: 0.0066 - val_loss: 0.0136 - val_accuracy: 0.0072\n",
      "Epoch 245/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0132 - accuracy: 0.0066 - val_loss: 0.0135 - val_accuracy: 0.0072\n",
      "Epoch 246/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0132 - accuracy: 0.0066 - val_loss: 0.0136 - val_accuracy: 0.0072\n",
      "Epoch 247/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0133 - accuracy: 0.0066 - val_loss: 0.0134 - val_accuracy: 0.0072\n",
      "Epoch 248/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0131 - accuracy: 0.0066 - val_loss: 0.0134 - val_accuracy: 0.0072\n",
      "Epoch 249/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0131 - accuracy: 0.0066 - val_loss: 0.0134 - val_accuracy: 0.0072\n",
      "Epoch 250/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0131 - accuracy: 0.0066 - val_loss: 0.0133 - val_accuracy: 0.0072\n",
      "Epoch 251/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0129 - accuracy: 0.0066 - val_loss: 0.0133 - val_accuracy: 0.0072\n",
      "Epoch 252/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0129 - accuracy: 0.0066 - val_loss: 0.0133 - val_accuracy: 0.0072\n",
      "Epoch 253/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0129 - accuracy: 0.0066 - val_loss: 0.0132 - val_accuracy: 0.0072\n",
      "Epoch 254/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0128 - accuracy: 0.0066 - val_loss: 0.0132 - val_accuracy: 0.0072\n",
      "Epoch 255/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0128 - accuracy: 0.0066 - val_loss: 0.0132 - val_accuracy: 0.0072\n",
      "Epoch 256/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0128 - accuracy: 0.0066 - val_loss: 0.0131 - val_accuracy: 0.0072\n",
      "Epoch 257/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0127 - accuracy: 0.0066 - val_loss: 0.0130 - val_accuracy: 0.0072\n",
      "Epoch 258/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0126 - accuracy: 0.0066 - val_loss: 0.0130 - val_accuracy: 0.0072\n",
      "Epoch 259/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0126 - accuracy: 0.0066 - val_loss: 0.0130 - val_accuracy: 0.0072\n",
      "Epoch 260/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0126 - accuracy: 0.0066 - val_loss: 0.0129 - val_accuracy: 0.0072\n",
      "Epoch 261/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0125 - accuracy: 0.0066 - val_loss: 0.0129 - val_accuracy: 0.0072\n",
      "Epoch 262/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0125 - accuracy: 0.0066 - val_loss: 0.0128 - val_accuracy: 0.0072\n",
      "Epoch 263/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0124 - accuracy: 0.0066 - val_loss: 0.0128 - val_accuracy: 0.0072\n",
      "Epoch 264/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0124 - accuracy: 0.0066 - val_loss: 0.0127 - val_accuracy: 0.0072\n",
      "Epoch 265/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0123 - accuracy: 0.0066 - val_loss: 0.0127 - val_accuracy: 0.0072\n",
      "Epoch 266/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0123 - accuracy: 0.0066 - val_loss: 0.0127 - val_accuracy: 0.0072\n",
      "Epoch 267/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0122 - accuracy: 0.0066 - val_loss: 0.0126 - val_accuracy: 0.0072\n",
      "Epoch 268/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0122 - accuracy: 0.0066 - val_loss: 0.0126 - val_accuracy: 0.0072\n",
      "Epoch 269/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0121 - accuracy: 0.0066 - val_loss: 0.0125 - val_accuracy: 0.0072\n",
      "Epoch 270/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0121 - accuracy: 0.0066 - val_loss: 0.0125 - val_accuracy: 0.0072\n",
      "Epoch 271/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0121 - accuracy: 0.0066 - val_loss: 0.0125 - val_accuracy: 0.0072\n",
      "Epoch 272/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0120 - accuracy: 0.0066 - val_loss: 0.0124 - val_accuracy: 0.0072\n",
      "Epoch 273/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0120 - accuracy: 0.0066 - val_loss: 0.0124 - val_accuracy: 0.0072\n",
      "Epoch 274/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0119 - accuracy: 0.0066 - val_loss: 0.0123 - val_accuracy: 0.0072\n",
      "Epoch 275/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0119 - accuracy: 0.0066 - val_loss: 0.0123 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0118 - accuracy: 0.0066 - val_loss: 0.0123 - val_accuracy: 0.0072\n",
      "Epoch 277/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0118 - accuracy: 0.0066 - val_loss: 0.0122 - val_accuracy: 0.0072\n",
      "Epoch 278/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0117 - accuracy: 0.0066 - val_loss: 0.0122 - val_accuracy: 0.0072\n",
      "Epoch 279/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0117 - accuracy: 0.0066 - val_loss: 0.0121 - val_accuracy: 0.0072\n",
      "Epoch 280/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0116 - accuracy: 0.0066 - val_loss: 0.0121 - val_accuracy: 0.0072\n",
      "Epoch 281/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0116 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0072\n",
      "Epoch 282/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0116 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0072\n",
      "Epoch 283/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0072\n",
      "Epoch 284/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0072\n",
      "Epoch 285/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0122 - val_accuracy: 0.0072\n",
      "Epoch 286/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0117 - accuracy: 0.0066 - val_loss: 0.0125 - val_accuracy: 0.0072\n",
      "Epoch 287/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0120 - accuracy: 0.0066 - val_loss: 0.0130 - val_accuracy: 0.0072\n",
      "Epoch 288/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0125 - accuracy: 0.0066 - val_loss: 0.0132 - val_accuracy: 0.0072\n",
      "Epoch 289/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0126 - accuracy: 0.0066 - val_loss: 0.0124 - val_accuracy: 0.0072\n",
      "Epoch 290/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0119 - accuracy: 0.0066 - val_loss: 0.0117 - val_accuracy: 0.0072\n",
      "Epoch 291/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0112 - accuracy: 0.0066 - val_loss: 0.0120 - val_accuracy: 0.0072\n",
      "Epoch 292/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0125 - val_accuracy: 0.0072\n",
      "Epoch 293/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0119 - accuracy: 0.0066 - val_loss: 0.0121 - val_accuracy: 0.0072\n",
      "Epoch 294/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0116 - val_accuracy: 0.0072\n",
      "Epoch 295/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0110 - accuracy: 0.0066 - val_loss: 0.0118 - val_accuracy: 0.0072\n",
      "Epoch 296/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0113 - accuracy: 0.0066 - val_loss: 0.0121 - val_accuracy: 0.0072\n",
      "Epoch 297/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0115 - accuracy: 0.0066 - val_loss: 0.0116 - val_accuracy: 0.0072\n",
      "Epoch 298/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0111 - accuracy: 0.0066 - val_loss: 0.0114 - val_accuracy: 0.0072\n",
      "Epoch 299/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0109 - accuracy: 0.0066 - val_loss: 0.0117 - val_accuracy: 0.0072\n",
      "Epoch 300/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0112 - accuracy: 0.0066 - val_loss: 0.0117 - val_accuracy: 0.0072\n",
      "Epoch 301/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0111 - accuracy: 0.0066 - val_loss: 0.0114 - val_accuracy: 0.0072\n",
      "Epoch 302/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0108 - accuracy: 0.0066 - val_loss: 0.0114 - val_accuracy: 0.0072\n",
      "Epoch 303/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0108 - accuracy: 0.0066 - val_loss: 0.0116 - val_accuracy: 0.0072\n",
      "Epoch 304/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0110 - accuracy: 0.0066 - val_loss: 0.0114 - val_accuracy: 0.0072\n",
      "Epoch 305/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0108 - accuracy: 0.0066 - val_loss: 0.0112 - val_accuracy: 0.0072\n",
      "Epoch 306/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0106 - accuracy: 0.0066 - val_loss: 0.0113 - val_accuracy: 0.0072\n",
      "Epoch 307/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0107 - accuracy: 0.0066 - val_loss: 0.0114 - val_accuracy: 0.0072\n",
      "Epoch 308/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0108 - accuracy: 0.0066 - val_loss: 0.0112 - val_accuracy: 0.0072\n",
      "Epoch 309/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0106 - accuracy: 0.0066 - val_loss: 0.0111 - val_accuracy: 0.0072\n",
      "Epoch 310/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0105 - accuracy: 0.0066 - val_loss: 0.0111 - val_accuracy: 0.0072\n",
      "Epoch 311/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0106 - accuracy: 0.0066 - val_loss: 0.0112 - val_accuracy: 0.0072\n",
      "Epoch 312/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0106 - accuracy: 0.0066 - val_loss: 0.0111 - val_accuracy: 0.0072\n",
      "Epoch 313/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0105 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 314/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0104 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 315/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0104 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 316/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0104 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 317/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0104 - accuracy: 0.0066 - val_loss: 0.0109 - val_accuracy: 0.0072\n",
      "Epoch 318/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0103 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n",
      "Epoch 319/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n",
      "Epoch 320/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n",
      "Epoch 321/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n",
      "Epoch 322/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0107 - val_accuracy: 0.0072\n",
      "Epoch 323/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0101 - accuracy: 0.0066 - val_loss: 0.0107 - val_accuracy: 0.0072\n",
      "Epoch 324/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0101 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 325/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 326/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 327/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 328/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 329/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0106 - val_accuracy: 0.0072\n",
      "Epoch 330/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0107 - val_accuracy: 0.0072\n",
      "Epoch 331/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0100 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0101 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 333/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0103 - accuracy: 0.0066 - val_loss: 0.0113 - val_accuracy: 0.0072\n",
      "Epoch 334/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0106 - accuracy: 0.0066 - val_loss: 0.0116 - val_accuracy: 0.0072\n",
      "Epoch 335/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0109 - accuracy: 0.0066 - val_loss: 0.0116 - val_accuracy: 0.0072\n",
      "Epoch 336/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0109 - accuracy: 0.0066 - val_loss: 0.0111 - val_accuracy: 0.0072\n",
      "Epoch 337/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0105 - accuracy: 0.0066 - val_loss: 0.0104 - val_accuracy: 0.0072\n",
      "Epoch 338/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0098 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 339/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0096 - accuracy: 0.0066 - val_loss: 0.0105 - val_accuracy: 0.0072\n",
      "Epoch 340/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0099 - accuracy: 0.0066 - val_loss: 0.0108 - val_accuracy: 0.0072\n",
      "Epoch 341/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0107 - val_accuracy: 0.0072\n",
      "Epoch 342/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0101 - accuracy: 0.0066 - val_loss: 0.0103 - val_accuracy: 0.0072\n",
      "Epoch 343/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 344/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0103 - val_accuracy: 0.0072\n",
      "Epoch 345/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0096 - accuracy: 0.0066 - val_loss: 0.0105 - val_accuracy: 0.0072\n",
      "Epoch 346/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0098 - accuracy: 0.0066 - val_loss: 0.0104 - val_accuracy: 0.0072\n",
      "Epoch 347/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 348/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 349/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 350/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 351/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 352/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0095 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 353/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 354/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 355/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 356/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 357/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 358/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 359/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 360/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 361/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 362/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 363/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 364/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 365/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 366/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 367/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 368/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 369/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 370/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 371/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 372/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0095 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 373/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 374/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 375/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0089 - accuracy: 0.0066 - val_loss: 0.0094 - val_accuracy: 0.0072\n",
      "Epoch 376/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0093 - val_accuracy: 0.0072\n",
      "Epoch 377/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0093 - val_accuracy: 0.0072\n",
      "Epoch 378/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0095 - val_accuracy: 0.0072\n",
      "Epoch 379/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 380/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 381/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 382/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 383/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0095 - val_accuracy: 0.0072\n",
      "Epoch 384/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0066 - val_loss: 0.0093 - val_accuracy: 0.0072\n",
      "Epoch 385/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 386/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 387/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 389/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 390/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0066 - val_loss: 0.0093 - val_accuracy: 0.0072\n",
      "Epoch 391/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0066 - val_loss: 0.0094 - val_accuracy: 0.0072\n",
      "Epoch 392/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 393/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0089 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 394/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 395/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 396/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0066 - val_loss: 0.0099 - val_accuracy: 0.0072\n",
      "Epoch 397/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0096 - val_accuracy: 0.0072\n",
      "Epoch 398/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0089 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 399/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 400/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 401/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 402/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0094 - val_accuracy: 0.0072\n",
      "Epoch 403/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0093 - val_accuracy: 0.0072\n",
      "Epoch 404/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 405/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 406/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 407/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 408/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 409/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0090 - val_accuracy: 0.0072\n",
      "Epoch 410/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0090 - val_accuracy: 0.0072\n",
      "Epoch 411/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0066 - val_loss: 0.0090 - val_accuracy: 0.0072\n",
      "Epoch 412/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 413/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 414/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 415/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 416/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 417/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0066 - val_loss: 0.0087 - val_accuracy: 0.0072\n",
      "Epoch 418/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0066 - val_loss: 0.0087 - val_accuracy: 0.0072\n",
      "Epoch 419/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 420/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 421/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0090 - val_accuracy: 0.0072\n",
      "Epoch 422/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 423/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 424/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0066 - val_loss: 0.0095 - val_accuracy: 0.0072\n",
      "Epoch 425/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0088 - accuracy: 0.0066 - val_loss: 0.0095 - val_accuracy: 0.0072\n",
      "Epoch 426/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0066 - val_loss: 0.0095 - val_accuracy: 0.0072\n",
      "Epoch 427/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 428/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 429/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 430/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 431/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 432/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 433/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 434/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 435/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0088 - val_accuracy: 0.0072\n",
      "Epoch 436/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 437/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 438/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 439/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 440/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 441/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 442/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 443/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 445/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 446/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 447/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 448/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0077 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 449/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0066 - val_loss: 0.0082 - val_accuracy: 0.0072\n",
      "Epoch 450/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0066 - val_loss: 0.0082 - val_accuracy: 0.0072\n",
      "Epoch 451/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0082 - val_accuracy: 0.0072\n",
      "Epoch 452/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 453/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 454/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 455/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0082 - val_accuracy: 0.0072\n",
      "Epoch 456/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0082 - val_accuracy: 0.0072\n",
      "Epoch 457/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 458/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 459/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 460/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0097 - val_accuracy: 0.0072\n",
      "Epoch 461/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0115 - val_accuracy: 0.0072\n",
      "Epoch 462/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0108 - accuracy: 0.0066 - val_loss: 0.0134 - val_accuracy: 0.0072\n",
      "Epoch 463/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0129 - accuracy: 0.0066 - val_loss: 0.0142 - val_accuracy: 0.0072\n",
      "Epoch 464/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0134 - accuracy: 0.0066 - val_loss: 0.0107 - val_accuracy: 0.0072\n",
      "Epoch 465/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0101 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 466/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 467/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 468/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0104 - accuracy: 0.0066 - val_loss: 0.0090 - val_accuracy: 0.0072\n",
      "Epoch 469/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 470/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 471/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 472/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0084 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 473/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0092 - val_accuracy: 0.0072\n",
      "Epoch 474/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 475/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 476/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0089 - val_accuracy: 0.0072\n",
      "Epoch 477/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 478/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 479/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0086 - val_accuracy: 0.0072\n",
      "Epoch 480/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 481/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 482/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 483/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 484/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 485/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0083 - val_accuracy: 0.0072\n",
      "Epoch 486/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 487/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 488/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 489/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 490/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 491/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 492/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 493/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 494/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 495/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 496/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 497/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 498/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 499/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 501/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 502/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 503/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 504/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 505/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 506/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 507/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 508/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 509/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 510/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 511/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0078 - val_accuracy: 0.0072\n",
      "Epoch 512/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 513/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 514/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 515/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 516/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 517/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 518/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 519/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 520/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 521/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 522/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 523/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 524/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 525/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 526/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 527/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 528/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 529/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 530/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 531/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 532/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 533/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 534/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 535/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 536/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 537/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 538/600\n",
      "7236/7236 [==============================] - 12s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 539/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 540/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 541/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 542/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 543/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 544/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 545/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 546/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 547/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 548/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 549/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 550/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 551/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 552/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 553/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 554/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 555/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 556/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 557/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 558/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 559/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 560/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 561/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 562/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 563/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 564/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 565/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 566/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 567/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 568/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 569/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0067 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 570/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 571/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 572/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 573/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 574/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 575/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0066 - val_loss: 0.0101 - val_accuracy: 0.0072\n",
      "Epoch 576/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0066 - val_loss: 0.0122 - val_accuracy: 0.0072\n",
      "Epoch 577/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0117 - accuracy: 0.0066 - val_loss: 0.0153 - val_accuracy: 0.0072\n",
      "Epoch 578/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0144 - accuracy: 0.0065 - val_loss: 0.0142 - val_accuracy: 0.0072\n",
      "Epoch 579/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0137 - accuracy: 0.0066 - val_loss: 0.0098 - val_accuracy: 0.0072\n",
      "Epoch 580/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 581/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0102 - val_accuracy: 0.0072\n",
      "Epoch 582/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0066 - val_loss: 0.0110 - val_accuracy: 0.0072\n",
      "Epoch 583/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0102 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 584/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0070 - accuracy: 0.0066 - val_loss: 0.0084 - val_accuracy: 0.0072\n",
      "Epoch 585/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0100 - val_accuracy: 0.0072\n",
      "Epoch 586/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 587/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 588/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0091 - val_accuracy: 0.0072\n",
      "Epoch 589/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 590/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 591/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0085 - val_accuracy: 0.0072\n",
      "Epoch 592/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0066 - val_loss: 0.0073 - val_accuracy: 0.0072\n",
      "Epoch 593/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0066 - val_loss: 0.0081 - val_accuracy: 0.0072\n",
      "Epoch 594/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0075 - accuracy: 0.0066 - val_loss: 0.0079 - val_accuracy: 0.0072\n",
      "Epoch 595/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0066 - val_loss: 0.0074 - val_accuracy: 0.0072\n",
      "Epoch 596/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0080 - val_accuracy: 0.0072\n",
      "Epoch 597/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0066 - val_loss: 0.0075 - val_accuracy: 0.0072\n",
      "Epoch 598/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0066 - val_loss: 0.0076 - val_accuracy: 0.0072\n",
      "Epoch 599/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0069 - accuracy: 0.0066 - val_loss: 0.0077 - val_accuracy: 0.0072\n",
      "Epoch 600/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0066 - val_loss: 0.0073 - val_accuracy: 0.0072\n",
      "(7236, 4, 10)\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_20 (LSTM)               (None, 4, 1024)           4239360   \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 4, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 4,240,385\n",
      "Trainable params: 4,240,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 7236 samples, validate on 1809 samples\n",
      "Epoch 1/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.4213 - accuracy: 0.0015 - val_loss: 0.3376 - val_accuracy: 0.0019\n",
      "Epoch 2/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.3423 - accuracy: 0.0015 - val_loss: 0.2682 - val_accuracy: 0.0019\n",
      "Epoch 3/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.2725 - accuracy: 0.0016 - val_loss: 0.2138 - val_accuracy: 0.0023\n",
      "Epoch 4/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.2181 - accuracy: 0.0019 - val_loss: 0.1793 - val_accuracy: 0.0028\n",
      "Epoch 5/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1834 - accuracy: 0.0020 - val_loss: 0.1652 - val_accuracy: 0.0030\n",
      "Epoch 6/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1685 - accuracy: 0.0021 - val_loss: 0.1565 - val_accuracy: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.1588 - accuracy: 0.0021 - val_loss: 0.1451 - val_accuracy: 0.0029\n",
      "Epoch 8/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1469 - accuracy: 0.0021 - val_loss: 0.1365 - val_accuracy: 0.0029\n",
      "Epoch 9/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1378 - accuracy: 0.0023 - val_loss: 0.1319 - val_accuracy: 0.0032\n",
      "Epoch 10/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.1327 - accuracy: 0.0023 - val_loss: 0.1300 - val_accuracy: 0.0032\n",
      "Epoch 11/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1304 - accuracy: 0.0023 - val_loss: 0.1265 - val_accuracy: 0.0033\n",
      "Epoch 12/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.1268 - accuracy: 0.0024 - val_loss: 0.1193 - val_accuracy: 0.0033\n",
      "Epoch 13/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.1194 - accuracy: 0.0024 - val_loss: 0.1100 - val_accuracy: 0.0033\n",
      "Epoch 14/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.1103 - accuracy: 0.0024 - val_loss: 0.1011 - val_accuracy: 0.0033\n",
      "Epoch 15/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.1017 - accuracy: 0.0024 - val_loss: 0.0941 - val_accuracy: 0.0033\n",
      "Epoch 16/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0951 - accuracy: 0.0024 - val_loss: 0.0902 - val_accuracy: 0.0033\n",
      "Epoch 17/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0915 - accuracy: 0.0025 - val_loss: 0.0893 - val_accuracy: 0.0033\n",
      "Epoch 18/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0907 - accuracy: 0.0025 - val_loss: 0.0896 - val_accuracy: 0.0033\n",
      "Epoch 19/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0909 - accuracy: 0.0026 - val_loss: 0.0883 - val_accuracy: 0.0033\n",
      "Epoch 20/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0896 - accuracy: 0.0026 - val_loss: 0.0851 - val_accuracy: 0.0033\n",
      "Epoch 21/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0864 - accuracy: 0.0026 - val_loss: 0.0810 - val_accuracy: 0.0033\n",
      "Epoch 22/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0823 - accuracy: 0.0026 - val_loss: 0.0773 - val_accuracy: 0.0033\n",
      "Epoch 23/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0785 - accuracy: 0.0026 - val_loss: 0.0743 - val_accuracy: 0.0033\n",
      "Epoch 24/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0753 - accuracy: 0.0026 - val_loss: 0.0716 - val_accuracy: 0.0033\n",
      "Epoch 25/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0724 - accuracy: 0.0026 - val_loss: 0.0690 - val_accuracy: 0.0033\n",
      "Epoch 26/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0696 - accuracy: 0.0025 - val_loss: 0.0668 - val_accuracy: 0.0033\n",
      "Epoch 27/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0671 - accuracy: 0.0025 - val_loss: 0.0657 - val_accuracy: 0.0033\n",
      "Epoch 28/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0658 - accuracy: 0.0025 - val_loss: 0.0654 - val_accuracy: 0.0033\n",
      "Epoch 29/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0655 - accuracy: 0.0025 - val_loss: 0.0648 - val_accuracy: 0.0033\n",
      "Epoch 30/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0648 - accuracy: 0.0025 - val_loss: 0.0634 - val_accuracy: 0.0033\n",
      "Epoch 31/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0634 - accuracy: 0.0025 - val_loss: 0.0614 - val_accuracy: 0.0033\n",
      "Epoch 32/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0614 - accuracy: 0.0025 - val_loss: 0.0594 - val_accuracy: 0.0033\n",
      "Epoch 33/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0594 - accuracy: 0.0025 - val_loss: 0.0575 - val_accuracy: 0.0033\n",
      "Epoch 34/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0577 - accuracy: 0.0025 - val_loss: 0.0557 - val_accuracy: 0.0033\n",
      "Epoch 35/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0559 - accuracy: 0.0026 - val_loss: 0.0538 - val_accuracy: 0.0033\n",
      "Epoch 36/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0542 - accuracy: 0.0026 - val_loss: 0.0524 - val_accuracy: 0.0033\n",
      "Epoch 37/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0528 - accuracy: 0.0026 - val_loss: 0.0516 - val_accuracy: 0.0033\n",
      "Epoch 38/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0520 - accuracy: 0.0026 - val_loss: 0.0509 - val_accuracy: 0.0033\n",
      "Epoch 39/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0514 - accuracy: 0.0026 - val_loss: 0.0501 - val_accuracy: 0.0035\n",
      "Epoch 40/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0505 - accuracy: 0.0026 - val_loss: 0.0490 - val_accuracy: 0.0035\n",
      "Epoch 41/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0495 - accuracy: 0.0026 - val_loss: 0.0479 - val_accuracy: 0.0036\n",
      "Epoch 42/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0484 - accuracy: 0.0026 - val_loss: 0.0469 - val_accuracy: 0.0036\n",
      "Epoch 43/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0475 - accuracy: 0.0026 - val_loss: 0.0461 - val_accuracy: 0.0036\n",
      "Epoch 44/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0465 - accuracy: 0.0026 - val_loss: 0.0452 - val_accuracy: 0.0036\n",
      "Epoch 45/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0456 - accuracy: 0.0026 - val_loss: 0.0443 - val_accuracy: 0.0036\n",
      "Epoch 46/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0446 - accuracy: 0.0026 - val_loss: 0.0436 - val_accuracy: 0.0036\n",
      "Epoch 47/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0438 - accuracy: 0.0026 - val_loss: 0.0430 - val_accuracy: 0.0036\n",
      "Epoch 48/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0432 - accuracy: 0.0026 - val_loss: 0.0424 - val_accuracy: 0.0036\n",
      "Epoch 49/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0425 - accuracy: 0.0026 - val_loss: 0.0417 - val_accuracy: 0.0036\n",
      "Epoch 50/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0418 - accuracy: 0.0026 - val_loss: 0.0410 - val_accuracy: 0.0036\n",
      "Epoch 51/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0410 - accuracy: 0.0026 - val_loss: 0.0402 - val_accuracy: 0.0036\n",
      "Epoch 52/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0403 - accuracy: 0.0026 - val_loss: 0.0395 - val_accuracy: 0.0036\n",
      "Epoch 53/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0397 - accuracy: 0.0026 - val_loss: 0.0388 - val_accuracy: 0.0037\n",
      "Epoch 54/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0389 - accuracy: 0.0026 - val_loss: 0.0380 - val_accuracy: 0.0037\n",
      "Epoch 55/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0382 - accuracy: 0.0026 - val_loss: 0.0373 - val_accuracy: 0.0037\n",
      "Epoch 56/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0375 - accuracy: 0.0027 - val_loss: 0.0367 - val_accuracy: 0.0037\n",
      "Epoch 57/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0369 - accuracy: 0.0027 - val_loss: 0.0361 - val_accuracy: 0.0037\n",
      "Epoch 58/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0363 - accuracy: 0.0027 - val_loss: 0.0355 - val_accuracy: 0.0037\n",
      "Epoch 59/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0357 - accuracy: 0.0027 - val_loss: 0.0349 - val_accuracy: 0.0037\n",
      "Epoch 60/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0351 - accuracy: 0.0027 - val_loss: 0.0343 - val_accuracy: 0.0037\n",
      "Epoch 61/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0345 - accuracy: 0.0027 - val_loss: 0.0337 - val_accuracy: 0.0037\n",
      "Epoch 62/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0339 - accuracy: 0.0027 - val_loss: 0.0331 - val_accuracy: 0.0037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0333 - accuracy: 0.0027 - val_loss: 0.0325 - val_accuracy: 0.0037\n",
      "Epoch 64/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0327 - accuracy: 0.0028 - val_loss: 0.0319 - val_accuracy: 0.0037\n",
      "Epoch 65/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0320 - accuracy: 0.0028 - val_loss: 0.0313 - val_accuracy: 0.0037\n",
      "Epoch 66/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0314 - accuracy: 0.0028 - val_loss: 0.0307 - val_accuracy: 0.0037\n",
      "Epoch 67/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0308 - accuracy: 0.0028 - val_loss: 0.0301 - val_accuracy: 0.0037\n",
      "Epoch 68/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0302 - accuracy: 0.0028 - val_loss: 0.0295 - val_accuracy: 0.0039\n",
      "Epoch 69/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0296 - accuracy: 0.0028 - val_loss: 0.0289 - val_accuracy: 0.0039\n",
      "Epoch 70/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0291 - accuracy: 0.0028 - val_loss: 0.0284 - val_accuracy: 0.0039\n",
      "Epoch 71/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0285 - accuracy: 0.0028 - val_loss: 0.0278 - val_accuracy: 0.0039\n",
      "Epoch 72/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0279 - accuracy: 0.0028 - val_loss: 0.0272 - val_accuracy: 0.0039\n",
      "Epoch 73/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0273 - accuracy: 0.0028 - val_loss: 0.0266 - val_accuracy: 0.0039\n",
      "Epoch 74/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0267 - accuracy: 0.0028 - val_loss: 0.0261 - val_accuracy: 0.0039\n",
      "Epoch 75/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0262 - accuracy: 0.0028 - val_loss: 0.0255 - val_accuracy: 0.0039\n",
      "Epoch 76/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0256 - accuracy: 0.0028 - val_loss: 0.0249 - val_accuracy: 0.0039\n",
      "Epoch 77/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0251 - accuracy: 0.0028 - val_loss: 0.0244 - val_accuracy: 0.0039\n",
      "Epoch 78/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0245 - accuracy: 0.0028 - val_loss: 0.0239 - val_accuracy: 0.0039\n",
      "Epoch 79/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0240 - accuracy: 0.0028 - val_loss: 0.0233 - val_accuracy: 0.0039\n",
      "Epoch 80/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0235 - accuracy: 0.0028 - val_loss: 0.0228 - val_accuracy: 0.0039\n",
      "Epoch 81/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0229 - accuracy: 0.0028 - val_loss: 0.0223 - val_accuracy: 0.0039\n",
      "Epoch 82/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0224 - accuracy: 0.0028 - val_loss: 0.0218 - val_accuracy: 0.0039\n",
      "Epoch 83/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0219 - accuracy: 0.0028 - val_loss: 0.0213 - val_accuracy: 0.0039\n",
      "Epoch 84/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0214 - accuracy: 0.0028 - val_loss: 0.0208 - val_accuracy: 0.0039\n",
      "Epoch 85/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0209 - accuracy: 0.0028 - val_loss: 0.0204 - val_accuracy: 0.0039\n",
      "Epoch 86/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0204 - accuracy: 0.0028 - val_loss: 0.0199 - val_accuracy: 0.0039\n",
      "Epoch 87/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0199 - accuracy: 0.0028 - val_loss: 0.0194 - val_accuracy: 0.0039\n",
      "Epoch 88/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0195 - accuracy: 0.0028 - val_loss: 0.0190 - val_accuracy: 0.0039\n",
      "Epoch 89/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0190 - accuracy: 0.0028 - val_loss: 0.0185 - val_accuracy: 0.0039\n",
      "Epoch 90/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0185 - accuracy: 0.0028 - val_loss: 0.0181 - val_accuracy: 0.0039\n",
      "Epoch 91/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0181 - accuracy: 0.0028 - val_loss: 0.0176 - val_accuracy: 0.0039\n",
      "Epoch 92/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0177 - accuracy: 0.0028 - val_loss: 0.0172 - val_accuracy: 0.0039\n",
      "Epoch 93/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0172 - accuracy: 0.0028 - val_loss: 0.0168 - val_accuracy: 0.0039\n",
      "Epoch 94/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0168 - accuracy: 0.0028 - val_loss: 0.0164 - val_accuracy: 0.0039\n",
      "Epoch 95/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0164 - accuracy: 0.0028 - val_loss: 0.0160 - val_accuracy: 0.0039\n",
      "Epoch 96/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0160 - accuracy: 0.0028 - val_loss: 0.0157 - val_accuracy: 0.0039\n",
      "Epoch 97/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0157 - accuracy: 0.0028 - val_loss: 0.0153 - val_accuracy: 0.0039\n",
      "Epoch 98/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0153 - accuracy: 0.0028 - val_loss: 0.0150 - val_accuracy: 0.0039\n",
      "Epoch 99/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0150 - accuracy: 0.0028 - val_loss: 0.0146 - val_accuracy: 0.0039\n",
      "Epoch 100/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0146 - accuracy: 0.0028 - val_loss: 0.0143 - val_accuracy: 0.0039\n",
      "Epoch 101/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0143 - accuracy: 0.0028 - val_loss: 0.0140 - val_accuracy: 0.0039\n",
      "Epoch 102/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0140 - accuracy: 0.0028 - val_loss: 0.0137 - val_accuracy: 0.0039\n",
      "Epoch 103/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0137 - accuracy: 0.0028 - val_loss: 0.0134 - val_accuracy: 0.0039\n",
      "Epoch 104/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0134 - accuracy: 0.0028 - val_loss: 0.0132 - val_accuracy: 0.0039\n",
      "Epoch 105/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0131 - accuracy: 0.0028 - val_loss: 0.0129 - val_accuracy: 0.0039\n",
      "Epoch 106/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0128 - accuracy: 0.0028 - val_loss: 0.0126 - val_accuracy: 0.0039\n",
      "Epoch 107/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0126 - accuracy: 0.0028 - val_loss: 0.0124 - val_accuracy: 0.0039\n",
      "Epoch 108/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0124 - accuracy: 0.0028 - val_loss: 0.0122 - val_accuracy: 0.0039\n",
      "Epoch 109/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0121 - accuracy: 0.0028 - val_loss: 0.0120 - val_accuracy: 0.0039\n",
      "Epoch 110/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0119 - accuracy: 0.0028 - val_loss: 0.0118 - val_accuracy: 0.0039\n",
      "Epoch 111/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0117 - accuracy: 0.0028 - val_loss: 0.0116 - val_accuracy: 0.0039\n",
      "Epoch 112/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0115 - accuracy: 0.0028 - val_loss: 0.0114 - val_accuracy: 0.0039\n",
      "Epoch 113/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0114 - accuracy: 0.0028 - val_loss: 0.0113 - val_accuracy: 0.0039\n",
      "Epoch 114/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0112 - accuracy: 0.0028 - val_loss: 0.0111 - val_accuracy: 0.0039\n",
      "Epoch 115/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0111 - accuracy: 0.0028 - val_loss: 0.0110 - val_accuracy: 0.0039\n",
      "Epoch 116/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0109 - accuracy: 0.0028 - val_loss: 0.0109 - val_accuracy: 0.0039\n",
      "Epoch 117/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0108 - accuracy: 0.0028 - val_loss: 0.0107 - val_accuracy: 0.0039\n",
      "Epoch 118/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0107 - accuracy: 0.0028 - val_loss: 0.0106 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0106 - accuracy: 0.0028 - val_loss: 0.0105 - val_accuracy: 0.0039\n",
      "Epoch 120/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0105 - accuracy: 0.0028 - val_loss: 0.0104 - val_accuracy: 0.0039\n",
      "Epoch 121/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0104 - accuracy: 0.0028 - val_loss: 0.0104 - val_accuracy: 0.0039\n",
      "Epoch 122/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0103 - accuracy: 0.0028 - val_loss: 0.0103 - val_accuracy: 0.0039\n",
      "Epoch 123/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0102 - accuracy: 0.0028 - val_loss: 0.0102 - val_accuracy: 0.0039\n",
      "Epoch 124/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0101 - accuracy: 0.0028 - val_loss: 0.0101 - val_accuracy: 0.0039\n",
      "Epoch 125/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0101 - accuracy: 0.0028 - val_loss: 0.0101 - val_accuracy: 0.0039\n",
      "Epoch 126/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0100 - accuracy: 0.0028 - val_loss: 0.0100 - val_accuracy: 0.0039\n",
      "Epoch 127/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0099 - accuracy: 0.0028 - val_loss: 0.0100 - val_accuracy: 0.0039\n",
      "Epoch 128/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0099 - accuracy: 0.0028 - val_loss: 0.0099 - val_accuracy: 0.0039\n",
      "Epoch 129/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0098 - accuracy: 0.0028 - val_loss: 0.0099 - val_accuracy: 0.0039\n",
      "Epoch 130/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0098 - accuracy: 0.0028 - val_loss: 0.0098 - val_accuracy: 0.0039\n",
      "Epoch 131/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0028 - val_loss: 0.0098 - val_accuracy: 0.0039\n",
      "Epoch 132/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0028 - val_loss: 0.0098 - val_accuracy: 0.0039\n",
      "Epoch 133/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0097 - accuracy: 0.0028 - val_loss: 0.0097 - val_accuracy: 0.0039\n",
      "Epoch 134/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0096 - accuracy: 0.0028 - val_loss: 0.0097 - val_accuracy: 0.0039\n",
      "Epoch 135/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0096 - accuracy: 0.0028 - val_loss: 0.0097 - val_accuracy: 0.0039\n",
      "Epoch 136/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0096 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 137/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 138/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 139/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0095 - accuracy: 0.0028 - val_loss: 0.0095 - val_accuracy: 0.0039\n",
      "Epoch 140/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0028 - val_loss: 0.0095 - val_accuracy: 0.0039\n",
      "Epoch 141/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0028 - val_loss: 0.0095 - val_accuracy: 0.0039\n",
      "Epoch 142/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0028 - val_loss: 0.0095 - val_accuracy: 0.0039\n",
      "Epoch 143/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0094 - val_accuracy: 0.0039\n",
      "Epoch 144/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0094 - val_accuracy: 0.0039\n",
      "Epoch 145/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0094 - val_accuracy: 0.0039\n",
      "Epoch 146/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0094 - val_accuracy: 0.0039\n",
      "Epoch 147/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0028 - val_loss: 0.0093 - val_accuracy: 0.0039\n",
      "Epoch 148/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0092 - accuracy: 0.0028 - val_loss: 0.0093 - val_accuracy: 0.0039\n",
      "Epoch 149/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0028 - val_loss: 0.0093 - val_accuracy: 0.0039\n",
      "Epoch 150/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0028 - val_loss: 0.0093 - val_accuracy: 0.0039\n",
      "Epoch 151/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0091 - accuracy: 0.0028 - val_loss: 0.0093 - val_accuracy: 0.0039\n",
      "Epoch 152/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0028 - val_loss: 0.0092 - val_accuracy: 0.0039\n",
      "Epoch 153/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0091 - accuracy: 0.0028 - val_loss: 0.0092 - val_accuracy: 0.0039\n",
      "Epoch 154/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0091 - accuracy: 0.0028 - val_loss: 0.0092 - val_accuracy: 0.0039\n",
      "Epoch 155/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0028 - val_loss: 0.0092 - val_accuracy: 0.0039\n",
      "Epoch 156/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 157/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 158/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0090 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 159/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 160/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 161/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 162/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 163/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 164/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 165/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 166/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 167/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 168/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0088 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 169/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 170/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 171/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 172/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 173/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 174/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 176/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 177/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 178/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 179/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 180/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 181/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 182/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 183/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 184/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 185/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 186/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 187/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 188/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 189/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 190/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 191/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 192/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0094 - accuracy: 0.0028 - val_loss: 0.0094 - val_accuracy: 0.0039\n",
      "Epoch 193/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 194/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 195/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0091 - val_accuracy: 0.0039\n",
      "Epoch 196/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0089 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 197/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0085 - val_accuracy: 0.0039\n",
      "Epoch 198/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0028 - val_loss: 0.0088 - val_accuracy: 0.0039\n",
      "Epoch 199/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0086 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 200/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 201/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 202/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 203/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 204/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 205/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0085 - val_accuracy: 0.0039\n",
      "Epoch 206/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0082 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 207/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0085 - val_accuracy: 0.0039\n",
      "Epoch 208/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0083 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 209/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 210/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 211/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0082 - accuracy: 0.0028 - val_loss: 0.0083 - val_accuracy: 0.0039\n",
      "Epoch 212/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0083 - val_accuracy: 0.0039\n",
      "Epoch 213/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0083 - val_accuracy: 0.0039\n",
      "Epoch 214/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 215/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0083 - val_accuracy: 0.0039\n",
      "Epoch 216/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0083 - val_accuracy: 0.0039\n",
      "Epoch 217/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 218/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 219/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 220/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0080 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 221/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 222/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 223/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 224/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 225/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 226/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 227/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 228/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0081 - val_accuracy: 0.0039\n",
      "Epoch 229/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 230/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 232/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0078 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 233/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 234/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 235/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 236/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 237/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 238/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 239/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 240/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 241/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 242/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 243/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 244/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 245/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 246/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 247/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 248/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 249/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 250/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 251/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 252/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 253/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0028 - val_loss: 0.0077 - val_accuracy: 0.0039\n",
      "Epoch 254/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0074 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 255/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0074 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 256/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 257/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 258/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 259/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0076 - val_accuracy: 0.0039\n",
      "Epoch 260/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 261/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0073 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 262/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 263/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 264/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 265/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 266/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 267/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 268/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 269/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 270/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 271/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 272/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 273/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 274/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 275/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 276/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n",
      "Epoch 277/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0084 - val_accuracy: 0.0039\n",
      "Epoch 278/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0081 - accuracy: 0.0028 - val_loss: 0.0090 - val_accuracy: 0.0039\n",
      "Epoch 279/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0087 - accuracy: 0.0028 - val_loss: 0.0087 - val_accuracy: 0.0039\n",
      "Epoch 280/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0084 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 281/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 282/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 283/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0080 - val_accuracy: 0.0039\n",
      "Epoch 284/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 285/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0028 - val_loss: 0.0074 - val_accuracy: 0.0039\n",
      "Epoch 286/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0071 - accuracy: 0.0028 - val_loss: 0.0078 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 288/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0028 - val_loss: 0.0071 - val_accuracy: 0.0039\n",
      "Epoch 289/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0068 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 290/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 291/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0028 - val_loss: 0.0071 - val_accuracy: 0.0039\n",
      "Epoch 292/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 293/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 294/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0028 - val_loss: 0.0070 - val_accuracy: 0.0039\n",
      "Epoch 295/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 296/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 297/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0028 - val_loss: 0.0070 - val_accuracy: 0.0039\n",
      "Epoch 298/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0028 - val_loss: 0.0070 - val_accuracy: 0.0039\n",
      "Epoch 299/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0067 - accuracy: 0.0028 - val_loss: 0.0071 - val_accuracy: 0.0039\n",
      "Epoch 300/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 301/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0070 - val_accuracy: 0.0039\n",
      "Epoch 302/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0070 - val_accuracy: 0.0039\n",
      "Epoch 303/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0067 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 304/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 305/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 306/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 307/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 308/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0065 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 309/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0065 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 310/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0065 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 311/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0065 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 312/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0068 - val_accuracy: 0.0039\n",
      "Epoch 313/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0065 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 314/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 315/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 316/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 317/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 318/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 319/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 320/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 321/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 322/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 323/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 324/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 325/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 326/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 327/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 328/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 329/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 330/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0062 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 331/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 332/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 333/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 334/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 335/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 336/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 337/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 338/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 339/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 340/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 341/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 342/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 344/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 345/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 346/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 347/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 348/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 349/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0075 - val_accuracy: 0.0039\n",
      "Epoch 350/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0072 - accuracy: 0.0028 - val_loss: 0.0089 - val_accuracy: 0.0039\n",
      "Epoch 351/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0085 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 352/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0092 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 353/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0061 - val_accuracy: 0.0039\n",
      "Epoch 354/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0058 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 355/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0068 - accuracy: 0.0028 - val_loss: 0.0079 - val_accuracy: 0.0039\n",
      "Epoch 356/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0076 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 357/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 358/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0061 - accuracy: 0.0028 - val_loss: 0.0073 - val_accuracy: 0.0039\n",
      "Epoch 359/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0070 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 360/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 361/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0069 - val_accuracy: 0.0039\n",
      "Epoch 362/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0066 - accuracy: 0.0028 - val_loss: 0.0062 - val_accuracy: 0.0039\n",
      "Epoch 363/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 364/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 365/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0061 - val_accuracy: 0.0039\n",
      "Epoch 366/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0057 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 367/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 368/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 369/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 370/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0062 - val_accuracy: 0.0039\n",
      "Epoch 371/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0058 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 372/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0062 - val_accuracy: 0.0039\n",
      "Epoch 373/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 374/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0057 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 375/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0061 - val_accuracy: 0.0039\n",
      "Epoch 376/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0058 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 377/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 378/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 379/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0057 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 380/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 381/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 382/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 383/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 384/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 385/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 386/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0059 - val_accuracy: 0.0039\n",
      "Epoch 387/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 388/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0055 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 389/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 390/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 391/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 392/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 393/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 394/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 395/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 396/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 397/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 398/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0057 - val_accuracy: 0.0039\n",
      "Epoch 400/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 401/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 402/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 403/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 404/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 405/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 406/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 407/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 408/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 409/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 410/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 411/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 412/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 413/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 414/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 415/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 416/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 417/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 418/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 419/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 420/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 421/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 422/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 423/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 424/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 425/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 426/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 427/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 428/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 429/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 430/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 431/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 432/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 433/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 434/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 435/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 436/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 437/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0062 - val_accuracy: 0.0039\n",
      "Epoch 438/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0058 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 439/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0117 - val_accuracy: 0.0039\n",
      "Epoch 440/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0113 - accuracy: 0.0028 - val_loss: 0.0127 - val_accuracy: 0.0039\n",
      "Epoch 441/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0121 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 442/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 443/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0096 - val_accuracy: 0.0039\n",
      "Epoch 444/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0091 - accuracy: 0.0028 - val_loss: 0.0067 - val_accuracy: 0.0039\n",
      "Epoch 445/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0064 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 446/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 447/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0077 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 448/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 449/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0065 - val_accuracy: 0.0039\n",
      "Epoch 450/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 451/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0066 - val_accuracy: 0.0039\n",
      "Epoch 452/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0063 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 453/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 454/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 456/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 457/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 458/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 459/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 460/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0058 - val_accuracy: 0.0039\n",
      "Epoch 461/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0053 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 462/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0055 - val_accuracy: 0.0039\n",
      "Epoch 463/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0051 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 464/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 465/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 466/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 467/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0054 - val_accuracy: 0.0039\n",
      "Epoch 468/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0050 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 469/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 470/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0049 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 471/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0053 - val_accuracy: 0.0039\n",
      "Epoch 472/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 473/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 474/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 475/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0048 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 476/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 477/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 478/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 479/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 480/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 481/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 482/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 483/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 484/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 485/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 486/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 487/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 488/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 489/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 490/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0050 - val_accuracy: 0.0039\n",
      "Epoch 491/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 492/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 493/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 494/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 495/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 496/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 497/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 498/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 499/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 500/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 501/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 502/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 503/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 504/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 505/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 506/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 507/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 508/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 509/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 510/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 512/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0044 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 513/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 514/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 515/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 516/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 517/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 518/600\n",
      "7236/7236 [==============================] - 11s 2ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 519/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 520/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 521/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 522/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 523/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 524/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 525/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 526/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 527/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 528/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 529/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 530/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 531/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 532/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 533/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 534/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 535/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 536/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 537/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 538/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 539/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 540/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 541/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 542/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 543/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 544/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 545/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 546/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 547/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 548/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 549/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 550/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 551/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 552/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 553/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0045 - val_accuracy: 0.0039\n",
      "Epoch 554/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 555/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 556/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 557/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 558/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 559/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 560/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 561/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 562/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 563/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 564/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 565/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 566/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 568/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0043 - val_accuracy: 0.0039\n",
      "Epoch 569/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 570/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 571/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0048 - val_accuracy: 0.0039\n",
      "Epoch 572/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0056 - val_accuracy: 0.0039\n",
      "Epoch 573/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0052 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 574/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0075 - accuracy: 0.0028 - val_loss: 0.0126 - val_accuracy: 0.0039\n",
      "Epoch 575/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0123 - accuracy: 0.0028 - val_loss: 0.0150 - val_accuracy: 0.0039\n",
      "Epoch 576/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0141 - accuracy: 0.0028 - val_loss: 0.0082 - val_accuracy: 0.0039\n",
      "Epoch 577/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 578/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0100 - val_accuracy: 0.0039\n",
      "Epoch 579/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0093 - accuracy: 0.0028 - val_loss: 0.0072 - val_accuracy: 0.0039\n",
      "Epoch 580/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0069 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 581/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0086 - val_accuracy: 0.0039\n",
      "Epoch 582/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0079 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 583/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 584/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0056 - accuracy: 0.0028 - val_loss: 0.0064 - val_accuracy: 0.0039\n",
      "Epoch 585/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0059 - accuracy: 0.0028 - val_loss: 0.0046 - val_accuracy: 0.0039\n",
      "Epoch 586/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.0028 - val_loss: 0.0063 - val_accuracy: 0.0039\n",
      "Epoch 587/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0060 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 588/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0060 - val_accuracy: 0.0039\n",
      "Epoch 589/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0054 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 590/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 591/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 592/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0046 - accuracy: 0.0028 - val_loss: 0.0047 - val_accuracy: 0.0039\n",
      "Epoch 593/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0042 - accuracy: 0.0028 - val_loss: 0.0051 - val_accuracy: 0.0039\n",
      "Epoch 594/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 595/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0040 - accuracy: 0.0028 - val_loss: 0.0052 - val_accuracy: 0.0039\n",
      "Epoch 596/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0047 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 597/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 598/600\n",
      "7236/7236 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n",
      "Epoch 599/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0039 - accuracy: 0.0028 - val_loss: 0.0049 - val_accuracy: 0.0039\n",
      "Epoch 600/600\n",
      "7236/7236 [==============================] - 10s 1ms/step - loss: 0.0043 - accuracy: 0.0028 - val_loss: 0.0044 - val_accuracy: 0.0039\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import RepeatVector\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create our cross validation data structure\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(processed_data['x'], processed_data['y'],\n",
    "                                                                    test_size = 0.2)\n",
    "\n",
    "# Train for latitude and longitude location\n",
    "y_train_lat = np.array([[[features[0]] for features in y] for y in y_train], dtype = np.float64)\n",
    "y_test_lat = np.array([[[features[0]] for features in y] for y in y_test], dtype = np.float64)\n",
    "y_train_long = np.array([[[features[1]] for features in y] for y in y_train], dtype = np.float64)\n",
    "y_test_long = np.array([[[features[1]] for features in y] for y in y_test], dtype = np.float64)\n",
    "\n",
    "\n",
    "def bd_lstm_td(X_train, y_train, X_test, y_test, n_epochs = 500) :    \n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units = 512, return_sequences = True, dropout = 0.05),\n",
    "                            input_shape = (X_train.shape[1],X_train.shape[2])))\n",
    "    model.add(LSTM(units = 256, return_sequences = True, dropout = 0.05))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mse', optimizer='adadelta')\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train, y_train, batch_size = len(X_train), epochs = n_epochs,\n",
    "                        validation_data = (X_test, y_test))\n",
    "    return model, history\n",
    "\n",
    "def lstm_td(X_train, X_test, y_train, y_test, n_epochs= 300) :\n",
    "    print(X_train.shape)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 1024, input_shape = (4,10), return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train, y_train, batch_size = len(X_train), epochs = n_epochs, validation_data = (X_test, y_test))\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "model_lat, model_lat_history = lstm_td(X_train,X_test,  y_train_lat,  y_test_lat, n_epochs = 600)\n",
    "model_long, model_long_history = lstm_td(X_train, X_test, y_train_long,  y_test_long, n_epochs = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Performance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_lat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b86bf7b0f5c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m# Predict values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[0mlat_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_lat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[0mlong_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_long\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_lat' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "def ai_errors(predictions, observations, history = None) :\n",
    "    '''\n",
    "    PURPOSE: Provide descriptive statistics on the predicted output versus the observed measurments\n",
    "    METHOD:  Take the errors of the predictions and answers and then calculate standard descriptive statistics\n",
    "    INPUT:   predictions - 2D array of predictions of observed output\n",
    "             observations - 2D array measurements of observed output\n",
    "             history - Keras history model for displaying model loss, default is None if not available\n",
    "    OUTPUT:\n",
    "    '''\n",
    "    errors = [];\n",
    "    observations_array = [];\n",
    "    predictions_array = [];\n",
    "\n",
    "    for i in range(len(predictions)) :\n",
    "        for j in range(len(predictions[i])) :\n",
    "            # Calculate errors           \n",
    "            predictions_array.append(predictions[i][j]);\n",
    "            observations_array.append(observations[i][j]);        \n",
    "            error = predictions[i][j] - observations[i][j];\n",
    "            errors.append(error)\n",
    "    #acc= model_lat.evaluate(observations_array,predictions_array);\n",
    "    #print('acc: ' ,acc)\n",
    "    mse = mean_squared_error(observations_array, predictions_array);  \n",
    "    rms = sqrt(mse);\n",
    "    \n",
    "#  THE RMS OR root mean square calculation is almost equivalent to the STANDARD DEVIATION(std) in the error distribution\n",
    "#   The RMSE for your training and your test sets should be very similar if you have built a good model. If the RMSE for the\n",
    "#   test set is much higher than that of the training set, it is likely that you've badly over fit the data\n",
    "\n",
    "    print('\\n rms ',rms)\n",
    "    print('\\n mse ',mse)\n",
    "\n",
    "    # Display history and erros\n",
    "    plt.figure(1)\n",
    "    plt.hist(errors, bins = 50)\n",
    "    plt.title('error histogram')\n",
    "    plt.xlabel('error')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.figure(2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    return  pd.DataFrame(errors)\n",
    "\n",
    "# Predict values\n",
    "lat_predictions = model_lat.predict(X_test)\n",
    "long_predictions = model_long.predict(X_test)\n",
    "\n",
    "# print( '* *******LAT PREDICTION*******',lat_predictions )\n",
    "# print( '* *******LAT lat_predictions_scaled*******',lat_predictions_scaled )\n",
    "\n",
    "\n",
    "# Scale back our predictions\n",
    "\n",
    "# Latitude\n",
    "lat_predictions_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0] for lat in prediction])\n",
    "                          for prediction in lat_predictions]\n",
    "\n",
    "y_lat_test_scaled = [scaler.inverse_transform([[lat[0],0,0,0,0,0,0,0,0,0] for lat in observation])\n",
    "                     for observation in y_test_lat]\n",
    "# Longitude\n",
    "long_predictions_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0] for long in prediction])\n",
    "                           for prediction in long_predictions]\n",
    "y_long_test_scaled = [scaler.inverse_transform([[0,long[0],0,0,0,0,0,0,0,0] for long in observation])\n",
    "                      for observation in y_test_long]\n",
    "\n",
    "                      \n",
    "lat_predictions = [[pred[0] for pred in hurricanes_pred] for hurricanes_pred in lat_predictions_scaled]\n",
    "lat_observations = [[obsrv[0] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_lat_test_scaled]\n",
    "\n",
    "\n",
    "lat_error = ai_errors(lat_predictions, lat_observations, model_lat_history).describe()\n",
    "print('lat error \\n')\n",
    "print(lat_error)\n",
    "\n",
    "\n",
    "long_predictions = [[pred[1] for pred in hurricanes_pred] for hurricanes_pred in long_predictions_scaled]\n",
    "long_observations = [[obsrv[1] for obsrv in hurricanes_obsrv] for hurricanes_obsrv in y_long_test_scaled]\n",
    "\n",
    "long_error = ai_errors(long_predictions, long_observations, model_long_history).describe()\n",
    "print('long error \\n')\n",
    "print(long_error)\n",
    "\n",
    "#Plot \n",
    "\n",
    "sixh_lat_pred = [[lat[0]]for lat in lat_predictions]\n",
    "sixh_lat_test = [[lat[0]]for lat in lat_observations]\n",
    "# print('6 HOURS\\n')\n",
    "# print(sixh_lat_pred)\n",
    "\n",
    "# print('6 HOURS\\n')\n",
    "# print(sixh_lat_test[0:10])\n",
    "\n",
    "\n",
    "# LATITUDE PLOTS\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(sixh_lat_pred[0:150], color='red', label='Predicted Value')\n",
    "plt.plot(sixh_lat_test[0:150], color='blue', label='Hurricane Observation Values')\n",
    "plt.title('6 Hour Prediction - Latitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "twelve_lat_pred = [[lat[1]]for lat in lat_predictions]\n",
    "twelve_lat_test = [[lat[1]]for lat in lat_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(twelve_lat_pred[0:150], color='red', label='Predicted Value')\n",
    "plt.plot(twelve_lat_test[0:150], color='blue', label='Hurricane Observed Values')\n",
    "plt.title('12 Hour Prediction - Latitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "eighteen_lat_pred = [[lat[2]]for lat in lat_predictions]\n",
    "eighteen_lat_test = [[lat[2]]for lat in lat_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(eighteen_lat_pred[0:150], color='red', label='Predicted Value')\n",
    "plt.plot(eighteen_lat_test[0:150], color='blue', label='Hurricane Observed Values')\n",
    "plt.title('18 Hour Prediction - Latitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "twentyfour_lat_pred = [[lat[3]]for lat in lat_predictions]\n",
    "twentyfour_lat_test = [[lat[3]]for lat in lat_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(twentyfour_lat_pred[0:150], color='red', label='Predicted Value')\n",
    "plt.plot(twentyfour_lat_test[0:150], color='blue', label='Hurricane Observed Values')\n",
    "plt.title('24 Hour Prediction - Latitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "# Longitude Plots\n",
    "\n",
    "sixh_long_pred = [[long[0]]for long in long_predictions]\n",
    "sixh_long_test = [[long[0]]for long in long_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(sixh_long_pred[0:150], color='green', label='Predicted Value')\n",
    "plt.plot(sixh_long_test[0:150], color='magenta', label='Hurricane Observation Values')\n",
    "plt.title('6 Hour Prediction - Longitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "print('sixh_long_test :',sixh_long_test)\n",
    "\n",
    "\n",
    "\n",
    "twelve_long_pred = [[long[1]]for long in long_predictions]\n",
    "twelve_long_test = [[long[1]]for long in long_observations]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(twelve_long_pred[0:150], color='green', label='Predicted Value')\n",
    "plt.plot(twelve_long_test[0:150], color='magenta', label='Hurricane Observed Values')\n",
    "plt.title('12 Hour Prediction - Longitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "eighteen_long_pred = [[long[2]]for long in long_predictions]\n",
    "eighteen_long_test =[[long[2]]for long in long_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(eighteen_long_pred[0:150], color='green', label='Predicted Value')\n",
    "plt.plot(eighteen_long_test[0:150], color='magenta', label='Hurricane Observed Values')\n",
    "plt.title('18 Hour Prediction - Longitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "twentyfour_long_pred = [[long[3]]for long in long_predictions]\n",
    "twentyfour_long_test = [[long[3]]for long in long_observations]\n",
    "\n",
    "plt.figure(figsize=(15, 4), dpi=100)\n",
    "plt.plot(twentyfour_long_pred[0:150], color='green', label='Predicted Value')\n",
    "plt.plot(twentyfour_long_test[0:150], color='magenta', label='Hurricane Observed Values')\n",
    "plt.title('24 Hour Prediction - Longitude')\n",
    "plt.xlabel('Storm Instances 6 Hours Apart - Multiple storms ')\n",
    "plt.ylabel('Latitude Values Per Instance')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7236/7236 [==============================] - 4s 557us/step\n",
      "Accuracy: 0.66%\n",
      "None\n",
      "1809/1809 [==============================] - 1s 532us/step\n",
      "0.7186290808022022\n"
     ]
    }
   ],
   "source": [
    "acc= model_lat.evaluate(X_train,  y_train_lat)\n",
    "print(print(\"Accuracy: %.2f%%\" % (acc[1]*100))\n",
    ")\n",
    "\n",
    "acc= model_lat.evaluate(X_test,  y_test_lat)\n",
    "print( (acc[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 4, 1024)           4239360   \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 4, 1)              1025      \n",
      "=================================================================\n",
      "Total params: 4,240,385\n",
      "Trainable params: 4,240,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = 5 # Number of hurricanes\n",
    "\n",
    "# Graph the trajectories of the longest hurricanes (the ones that traveled the most)\n",
    "plt.figure(figsize=(10,5))\n",
    "m = Basemap(llcrnrlon=-110.,llcrnrlat=5.,urcrnrlon=10.,urcrnrlat=60.,\n",
    "            rsphere=(6378137.00,6356752.3142),\n",
    "            resolution='l',\n",
    "            projection='merc',\n",
    "            lat_0=40.,lon_0=-20.,lat_ts=20.)\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "m.drawmapboundary(fill_color='white')\n",
    "m.fillcontinents(color='#D3D3D3')\n",
    "m.drawparallels(np.arange(10,90,20),labels=[1,1,0,1])\n",
    "m.drawmeridians(np.arange(-180,180,30),labels=[1,1,0,1])\n",
    "\n",
    "for x in hurricane_amount.nlargest(n,0).index:\n",
    "    largest_hurr = data[data['unique-key'] == keys[x][1]]\n",
    "    lat = sixh_long_pred.values\n",
    "    long = largest_hurr['Long'].values\n",
    "    xpt, ypt = m(long, lat)\n",
    "    plt.text(xpt[len(lat) - 1]+100000,ypt[len(long) - 1]+100000, '%s (%s)' % (keys[x][1].split('-')[0],keys[x][1].split('-')[1]))\n",
    "    m.plot(xpt, ypt, linewidth=2, color='blue')\n",
    "    \n",
    "# plt.title('Top 5 Atlantic Hurricanes (Distance Traveled)')\n",
    "# plt.savefig('largest_dist_hurricanes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-b4dc8ee551a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mh_lat_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
